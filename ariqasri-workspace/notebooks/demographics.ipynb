{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f93c064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Extracted 524 Victoria SA2 regions\n",
      "Sample: [('Alfredton', (-37.54173636281507, 143.749330252453)), ('Ballarat', (-37.5561439450457, 143.83665489612585)), ('Buninyong', (-37.643854141582494, 143.880777903821)), ('Delacombe', (-37.58222851797997, 143.77847784283048)), ('Smythes Creek', (-37.62024909240558, 143.74623319717654))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/09/nwdnh9n512dflz62l4kfx0_r0000gn/T/ipykernel_42229/2737538597.py:12: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  vic[\"Lat\"] = vic.geometry.centroid.y\n",
      "/var/folders/09/nwdnh9n512dflz62l4kfx0_r0000gn/T/ipykernel_42229/2737538597.py:13: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  vic[\"Lng\"] = vic.geometry.centroid.x\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Load SA2 shapefile\n",
    "shapefile = \"/Users/ariqasri/Desktop/project-2-group-real-estate-industry-project-7-2025/ariqasri-workspace/dataset/SA2_GDA2020_SHAPEFILE/SA2_2021_AUST_GDA2020.shp\"\n",
    "gdf = gpd.read_file(shapefile)\n",
    "\n",
    "# 2. Filter Victoria (STE_CODE21 = \"2\")\n",
    "vic = gdf[gdf[\"STE_CODE21\"] == \"2\"].copy()\n",
    "\n",
    "# 3. Compute centroids\n",
    "vic[\"Lat\"] = vic.geometry.centroid.y\n",
    "vic[\"Lng\"] = vic.geometry.centroid.x\n",
    "\n",
    "# 4. Build dictionary (SA2_NAME21 → (Lat, Lng))\n",
    "suburbs = {\n",
    "    row[\"SA2_NAME21\"]: (row[\"Lat\"], row[\"Lng\"])\n",
    "    for _, row in vic.iterrows()\n",
    "}\n",
    "\n",
    "# 5. Save to CSV\n",
    "vic_out = vic[[\"SA2_NAME21\", \"Lat\", \"Lng\"]].rename(\n",
    "    columns={\"SA2_NAME21\": \"Cluster\"}\n",
    ")\n",
    "vic_out.to_csv(\"vic_clusters_centroids.csv\", index=False)\n",
    "\n",
    "print(\"✅ Extracted\", len(suburbs), \"Victoria SA2 regions\")\n",
    "print(\"Sample:\", list(suburbs.items())[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e8339a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: /Users/ariqasri/Desktop/project-2-group-real-estate-industry-project-7-2025/ariqasri-workspace/dataset/raw/mapped_target_suburbs.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# Load cluster centroids\n",
    "vic = pd.read_csv(\"/Users/ariqasri/Desktop/project-2-group-real-estate-industry-project-7-2025/ariqasri-workspace/dataset/raw/vic_clusters_centroids.csv\") \n",
    "\n",
    "# cleaning\n",
    "DIRECTIONALS = {\"north\", \"south\", \"east\", \"west\", \"upper\", \"lower\", \"central\", \"inner\", \"outer\"}\n",
    "STOP_TOKENS = DIRECTIONALS | {\"vic\", \"city\", \"road\", \"rd\"}\n",
    "\n",
    "def normalize_name(s: str) -> str:\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"\\(.*?\\)\", \"\", s)                 \n",
    "    s = s.replace(\"&\", \" and \")\n",
    "    s = re.sub(r\"[;/]\", \" \", s)\n",
    "    s = s.replace(\"–\", \" \").replace(\"-\", \" \")     \n",
    "    s = re.sub(r\"\\bst\\.?\\b\", \"st\", s)             \n",
    "    s = re.sub(r\"\\bmt\\.?\\b\", \"mount\", s)          \n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def tokenize_base(s: str):\n",
    "    norm = normalize_name(s)\n",
    "    toks = [t for t in re.split(r\"[^a-z0-9]+\", norm) if t]\n",
    "    base_toks = [t for t in toks if t not in STOP_TOKENS]\n",
    "    primary = base_toks[0] if base_toks else (toks[0] if toks else None)\n",
    "    return norm, toks, base_toks, primary\n",
    "\n",
    "vic = vic.copy()\n",
    "vic[\"cluster_norm\"] = vic[\"Cluster\"].apply(normalize_name)\n",
    "vic[\"tokens_all\"] = vic[\"cluster_norm\"].apply(lambda s: [t for t in re.split(r\"[^a-z0-9]+\", s) if t])\n",
    "vic[\"tokens_base\"] = vic[\"tokens_all\"].apply(lambda toks: [t for t in toks if t not in STOP_TOKENS])\n",
    "\n",
    "# fuzzy matching function\n",
    "def best_match(component: str):\n",
    "    comp_norm, comp_tokens, comp_base, comp_primary = tokenize_base(component)\n",
    "\n",
    "    # exact match\n",
    "    exact = vic[vic[\"cluster_norm\"] == comp_norm]\n",
    "    if not exact.empty:\n",
    "        return exact.iloc[0]\n",
    "\n",
    "    # filter primary token\n",
    "    if comp_primary:\n",
    "        cand = vic[vic[\"tokens_all\"].apply(lambda toks: comp_primary in toks)].copy()\n",
    "    else:\n",
    "        cand = vic.copy()\n",
    "\n",
    "    # check base token overlap\n",
    "    if comp_primary and len(comp_base) > 0:\n",
    "        cand[\"base_overlap\"] = cand[\"tokens_base\"].apply(lambda t: len(set(t) & set(comp_base)))\n",
    "        if cand[\"base_overlap\"].max() > 0:\n",
    "            cand = cand[cand[\"base_overlap\"] == cand[\"base_overlap\"].max()]\n",
    "\n",
    "    # fuzzy match\n",
    "    if not cand.empty:\n",
    "        cand_strings = cand[\"cluster_norm\"].tolist()\n",
    "        match, score, idx = process.extractOne(comp_norm, cand_strings, scorer=fuzz.token_set_ratio)\n",
    "        return cand.iloc[idx]\n",
    "\n",
    "    return None\n",
    "\n",
    "# map each suburb to a closest centroid\n",
    "def map_target_suburb(target: str):\n",
    "    parts = [p.strip() for p in re.split(r\"\\s*-\\s*\", target) if p.strip()]\n",
    "    matches, coords = [], []\n",
    "\n",
    "    for comp in parts:\n",
    "        row = best_match(comp)\n",
    "        if row is not None and pd.notnull(row[\"Lat\"]) and pd.notnull(row[\"Lng\"]):\n",
    "            matches.append(row[\"Cluster\"])\n",
    "            coords.append((row[\"Lat\"], row[\"Lng\"]))\n",
    "\n",
    "    if not coords:\n",
    "        return None, None, None\n",
    "\n",
    "    lat = sum(c[0] for c in coords) / len(coords)\n",
    "    lng = sum(c[1] for c in coords) / len(coords)\n",
    "    return \"; \".join(matches), lat, lng\n",
    "\n",
    "# target suburbs from excel\n",
    "target_suburbs = [\n",
    "    \"Albert Park-Middle Park-West St Kilda\",\n",
    "    \"Armadale\",\n",
    "    \"Carlton North\",\n",
    "    \"Carlton-Parkville\",\n",
    "    \"CBD-St Kilda Rd\",\n",
    "    \"Collingwood-Abbotsford\",\n",
    "    \"Docklands\",\n",
    "    \"East Melbourne\",\n",
    "    \"East St Kilda\",\n",
    "    \"Elwood\",\n",
    "    \"Fitzroy\",\n",
    "    \"Fitzroy North-Clifton Hill\",\n",
    "    \"Flemington-Kensington\",\n",
    "    \"North Melbourne-West Melbourne\",\n",
    "    \"Port Melbourne\",\n",
    "    \"Prahran-Windsor\",\n",
    "    \"Richmond-Burnley\",\n",
    "    \"South Melbourne\",\n",
    "    \"South Yarra\",\n",
    "    \"Southbank\",\n",
    "    \"St Kilda\",\n",
    "    \"Toorak\",\n",
    "    \"Balwyn\",\n",
    "    \"Blackburn\",\n",
    "    \"Box Hill\",\n",
    "    \"Bulleen-Templestowe-Doncaster\",\n",
    "    \"Burwood-Ashburton\",\n",
    "    \"Camberwell-Glen Iris\",\n",
    "    \"Canterbury-Surrey Hills-Mont Albert\",\n",
    "    \"Chadstone-Oakleigh\",\n",
    "    \"Clayton\",\n",
    "    \"Doncaster East-Donvale\",\n",
    "    \"East Hawthorn\",\n",
    "    \"Glen Waverley-Mulgrave\",\n",
    "    \"Hawthorn\",\n",
    "    \"Kew\",\n",
    "    \"Mount Waverley\",\n",
    "    \"Nunawading-Mitcham\",\n",
    "    \"Vermont-Forest Hill-Burwood East\",\n",
    "    \"Aspendale-Chelsea-Carrum\",\n",
    "    \"Bentleigh\",\n",
    "    \"Brighton\",\n",
    "    \"Brighton East\",\n",
    "    \"Carnegie\",\n",
    "    \"Caulfield\",\n",
    "    \"Cheltenham\",\n",
    "    \"Elsternwick\",\n",
    "    \"Hampton-Beaumaris\",\n",
    "    \"Malvern\",\n",
    "    \"Malvern East\",\n",
    "    \"Mentone-Parkdale-Mordialloc\",\n",
    "    \"Murrumbeena-Hughesdale\",\n",
    "    \"Altona\",\n",
    "    \"Footscray\",\n",
    "    \"Keilor East-Avondale Heights\",\n",
    "    \"Melton\",\n",
    "    \"Newport-Spotswood\",\n",
    "    \"St Albans-Deer Park\",\n",
    "    \"Sunshine\",\n",
    "    \"Sydenham\",\n",
    "    \"Werribee-Hoppers Crossing\",\n",
    "    \"West Footscray\",\n",
    "    \"Williamstown\",\n",
    "    \"Yarraville-Seddon\",\n",
    "    \"Broadmeadows-Roxburgh Park\",\n",
    "    \"Brunswick\",\n",
    "    \"Coburg-Pascoe Vale South\",\n",
    "    \"Craigieburn\",\n",
    "    \"East Brunswick\",\n",
    "    \"Essendon\",\n",
    "    \"Gladstone Park-Tullamarine\",\n",
    "    \"Keilor\",\n",
    "    \"Moonee Ponds-Ascot Vale\",\n",
    "    \"Oak Park-Glenroy-Fawkner\",\n",
    "    \"Pascoe Vale-Coburg North\",\n",
    "    \"Sunbury\",\n",
    "    \"West Brunswick\",\n",
    "    \"Bundoora-Greensborough-Hurstbridge\",\n",
    "    \"Eltham-Research-Montmorency\",\n",
    "    \"Fairfield-Alphington\",\n",
    "    \"Heidelberg-Heidelberg West\",\n",
    "    \"Ivanhoe-Ivanhoe East\",\n",
    "    \"Mill Park-Epping\",\n",
    "    \"Northcote\",\n",
    "    \"Preston\",\n",
    "    \"Reservoir\",\n",
    "    \"Thomastown-Lalor\",\n",
    "    \"Thornbury\",\n",
    "    \"Whittlesea\",\n",
    "    \"Bayswater\",\n",
    "    \"Boronia\",\n",
    "    \"Croydon-Lilydale\",\n",
    "    \"Ferntree Gully\",\n",
    "    \"Ringwood\",\n",
    "    \"Rowville\",\n",
    "    \"Wantirna-Scoresby\",\n",
    "    \"Yarra Ranges\",\n",
    "    \"Berwick\",\n",
    "    \"Cranbourne\",\n",
    "    \"Dandenong\",\n",
    "    \"Dandenong North-Endeavour Hills\",\n",
    "    \"Narre Warren-Hampton Park\",\n",
    "    \"Noble Park\",\n",
    "    \"Pakenham\",\n",
    "    \"Springvale\",\n",
    "    \"Dromana-Portsea\",\n",
    "    \"Frankston\",\n",
    "    \"Hastings-Flinders\",\n",
    "    \"Mt Eliza-Mornington-Mt Martha\",\n",
    "    \"Seaford-Carrum Downs\",\n",
    "    \"Belmont-Grovedale\",\n",
    "    \"Corio\",\n",
    "    \"Geelong-Newcombe\",\n",
    "    \"Herne Hill-Geelong West\",\n",
    "    \"Lara\",\n",
    "    \"Newtown\",\n",
    "    \"North Geelong\",\n",
    "    \"Ballarat\",\n",
    "    \"Mount Clear-Buninyong\",\n",
    "    \"Sebastopol-Delacombe\",\n",
    "    \"Wendouree-Alfredton\",\n",
    "    \"Bendigo\",\n",
    "    \"Flora Hill-Bendigo East\",\n",
    "    \"Golden Square-Kangaroo Flat\",\n",
    "    \"North Bendigo\",\n",
    "    \"Bairnsdale\",\n",
    "    \"Benalla\",\n",
    "    \"Castlemaine\",\n",
    "    \"Echuca\",\n",
    "    \"Hamilton\",\n",
    "    \"Horsham\",\n",
    "    \"Mildura\",\n",
    "    \"Moe-Newborough\",\n",
    "    \"Morwell\",\n",
    "    \"Ocean Grove-Barwon Heads\",\n",
    "    \"Portland\",\n",
    "    \"Sale-Maffra\",\n",
    "    \"Seymour\",\n",
    "    \"Shepparton\",\n",
    "    \"Swan Hill\",\n",
    "    \"Torquay\",\n",
    "    \"Traralgon\",\n",
    "    \"Wanagaratta\",\n",
    "    \"Warragul\",\n",
    "    \"Warrnambool\",\n",
    "    \"Wodonga\",\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for t in target_suburbs:\n",
    "    matched, lat, lng = map_target_suburb(t)\n",
    "    rows.append({\"Target_Suburb\": t, \"Matched_Cluster\": matched, \"Lat\": lat, \"Lng\": lng})\n",
    "\n",
    "mapped_fixed = pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "sa2 = gpd.read_file(\n",
    "    \"/Users/ariqasri/Desktop/project-2-group-real-estate-industry-project-7-2025/ariqasri-workspace/dataset/landing/SA2_GDA2020_SHAPEFILE/SA2_2021_AUST_GDA2020.shp\"\n",
    ")\n",
    "sa2_vic = sa2[sa2[\"STE_CODE21\"] == \"2\"].copy().to_crs(\"EPSG:4283\")\n",
    "\n",
    "# load lga\n",
    "lga = gpd.read_file(\n",
    "    \"/Users/ariqasri/Desktop/project-2-group-real-estate-industry-project-7-2025/ariqasri-workspace/dataset/landing/LGA_2021_AUST_GDA2020_SHP/LGA_2021_AUST_GDA2020.shp\"\n",
    ")\n",
    "lga_vic = lga[lga[\"STE_CODE21\"] == \"2\"].copy().to_crs(\"EPSG:4283\")\n",
    "\n",
    "# convert mapped centroids to geodataframe\n",
    "mapped_gdf = gpd.GeoDataFrame(\n",
    "    mapped_fixed,\n",
    "    geometry=[Point(xy) if pd.notnull(xy[0]) and pd.notnull(xy[1]) else None \n",
    "              for xy in zip(mapped_fixed[\"Lng\"], mapped_fixed[\"Lat\"])],\n",
    "    crs=\"EPSG:4283\"\n",
    ")\n",
    "\n",
    "# spatial join to SA2\n",
    "mapped_with_sa2 = gpd.sjoin(\n",
    "    mapped_gdf,\n",
    "    sa2_vic[[\"SA2_CODE21\", \"SA2_NAME21\", \"geometry\"]],\n",
    "    how=\"left\", predicate=\"within\"\n",
    ")\n",
    "if \"index_right\" in mapped_with_sa2.columns:\n",
    "    mapped_with_sa2 = mapped_with_sa2.drop(columns=[\"index_right\"])\n",
    "\n",
    "# spatial join to lga\n",
    "mapped_with_both = gpd.sjoin(\n",
    "    mapped_with_sa2,\n",
    "    lga_vic[[\"LGA_CODE21\", \"LGA_NAME21\", \"geometry\"]],\n",
    "    how=\"left\", predicate=\"within\"\n",
    ")\n",
    "\n",
    "mapped_with_both = mapped_with_both.drop(columns=[\"index_right\"])\n",
    "\n",
    "# save output\n",
    "output_path = \"/Users/ariqasri/Desktop/project-2-group-real-estate-industry-project-7-2025/ariqasri-workspace/dataset/raw/mapped_target_suburbs.csv\"\n",
    "mapped_with_both.drop(columns=\"geometry\").to_csv(output_path, index=False)\n",
    "\n",
    "\n",
    "print(\"Saved:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150369ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved results to: /Users/ariqasri/Desktop/project-2-group-real-estate-industry-project-7-2025/ariqasri-workspace/dataset/raw/demographics_dataset.csv\n",
      "                           Target_Suburb                      Matched_Cluster  \\\n",
      "0  Albert Park-Middle Park-West St Kilda         Albert Park; St Kilda - West   \n",
      "1                               Armadale                             Armadale   \n",
      "2                          Carlton North                              Carlton   \n",
      "3                      Carlton-Parkville                   Carlton; Parkville   \n",
      "4                        CBD-St Kilda Rd  Melbourne CBD - East; St Kilda East   \n",
      "\n",
      "         Lat         Lng   SA2_CODE21  earning_over_2000_per_week  \\\n",
      "0 -37.853484  144.970161  206051128.0                         8.0   \n",
      "1 -37.856747  145.020711  206061135.0                        26.0   \n",
      "2 -37.800500  144.967804  206041117.0                        15.0   \n",
      "3 -37.793796  144.959672  206041124.0                        15.0   \n",
      "4 -37.839927  144.983391  206041125.0                        14.5   \n",
      "\n",
      "   earning_under_1000_per_week  average_income  mortgage_repayments  \\\n",
      "0                         38.0           858.0               1842.0   \n",
      "1                         27.0          1378.0               3000.0   \n",
      "2                         32.0          1126.0                750.0   \n",
      "3                         32.0          1126.0                750.0   \n",
      "4                         35.0           991.0               2525.0   \n",
      "\n",
      "   tenant_rate  \n",
      "0         75.0  \n",
      "1         32.0  \n",
      "2         69.0  \n",
      "3         69.0  \n",
      "4         54.5  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# load datasets\n",
    "df = pd.read_csv(\n",
    "    \"/Users/ariqasri/Desktop/project-2-group-real-estate-industry-project-7-2025/ariqasri-workspace/dataset/raw/mapped_target_suburbs.csv\"\n",
    ")\n",
    "\n",
    "# filters valid lat and lng data\n",
    "valid_suburbs = df[df[\"Lat\"].notnull()].copy()\n",
    "\n",
    "# load vic clusters\n",
    "vic = pd.read_csv(\n",
    "    \"/Users/ariqasri/Desktop/project-2-group-real-estate-industry-project-7-2025/ariqasri-workspace/dataset/raw/vic_clusters_centroids.csv\"\n",
    ")\n",
    "\n",
    "# microburbs scraping\n",
    "def get_microburbs_stat(lat, lng, stat_name):\n",
    "    url = f\"https://www.microburbs.com.au/heat-map-value?stat_name={stat_name}&lat={lat}&lng={lng}\"\n",
    "    resp = requests.get(url)\n",
    "    if resp.status_code == 200:\n",
    "        text = resp.text.strip()\n",
    "        try:\n",
    "            if \"%\" in text:\n",
    "                val = float(text.split(\"%\")[0].strip())\n",
    "            elif \"$\" in text:  # e.g. \"$2000 per month\"\n",
    "                val = float(text.replace(\"$\", \"\").replace(\",\", \"\").split(\" \")[0])\n",
    "            else:\n",
    "                val = float(text.split(\" \")[0])\n",
    "            return np.nan if val == 0.0 else val\n",
    "        except Exception:\n",
    "            return np.nan\n",
    "    return np.nan\n",
    "\n",
    "# get stats for target variable\n",
    "def get_stats_for_target(target, clusters, metrics):\n",
    "    results = {m: [] for m in metrics}\n",
    "    for comp in clusters.split(\";\"):\n",
    "        comp = comp.strip()\n",
    "        row = vic[vic[\"Cluster\"] == comp]\n",
    "        if not row.empty:\n",
    "            lat, lng = row.iloc[0][\"Lat\"], row.iloc[0][\"Lng\"]\n",
    "            for m in metrics:\n",
    "                val = get_microburbs_stat(lat, lng, m)\n",
    "                if pd.notnull(val):\n",
    "                    results[m].append(val)\n",
    "            time.sleep(0.5)  \n",
    "    return {m: np.nanmean(results[m]) if results[m] else np.nan for m in metrics}\n",
    "\n",
    "# features\n",
    "metrics = [\n",
    "    \"earning_over_2000_per_week\",\n",
    "    \"earning_under_1000_per_week\",\n",
    "    \"average_income\",\n",
    "    \"mortgage_repayments\",\n",
    "    \"tenant_rate\"\n",
    "]\n",
    "\n",
    "# data\n",
    "rows = []\n",
    "for _, row in valid_suburbs.iterrows():\n",
    "    clusters = row[\"Matched_Cluster\"]\n",
    "    stats = get_stats_for_target(row[\"Target_Suburb\"], clusters, metrics)\n",
    "    \n",
    "    rows.append({\n",
    "        \"Target_Suburb\": row[\"Target_Suburb\"],\n",
    "        \"Matched_Cluster\": row[\"Matched_Cluster\"],\n",
    "        \"Lat\": row[\"Lat\"],\n",
    "        \"Lng\": row[\"Lng\"],\n",
    "        \"SA2_CODE21\": row[\"SA2_CODE21\"],   \n",
    "        **stats   \n",
    "    })\n",
    "\n",
    "# save output\n",
    "final_df = pd.DataFrame(rows)\n",
    "output_path = \"/Users/ariqasri/Desktop/project-2-group-real-estate-industry-project-7-2025/ariqasri-workspace/dataset/raw/demographics_dataset.csv\"\n",
    "final_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Saved results to:\", output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
