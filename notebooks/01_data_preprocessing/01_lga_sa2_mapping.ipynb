{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c7ff116",
   "metadata": {},
   "source": [
    "# Mapping Target Suburbs to SA2 Regions\n",
    "\n",
    "## Purpose\n",
    "Map target suburbs in Victoria to their corresponding SA2 and LGA regions using spatial joins and fuzzy string matching to clean and normalize suburb names.\n",
    "\n",
    "## Inputs\n",
    "- `SA2_2021_AUST_GDA2020.shp` – SA2 polygons for Victoria.  \n",
    "- `LGA_2021_AUST_GDA2020.shp` – LGA polygons for Victoria.  \n",
    "\n",
    "## Outputs\n",
    "- `mapped_target_suburbs.csv` – target suburbs matched to SA2 and LGA with coordinates.\n",
    "\n",
    "## Key Steps\n",
    "1. Load SA2 and LGA shapefiles for Victoria and compute centroids for SA2s.  \n",
    "2. Normalize and tokenize suburb/cluster names to remove directional terms and common stop words.  \n",
    "3. Define function to match target components to clusters using exact, token-based, and fuzzy matching.  \n",
    "4. Map target suburbs to clusters, computing average coordinates when multiple matches occur.  \n",
    "5. Create GeoDataFrame of mapped suburbs and perform spatial joins with SA2 and LGA polygons.  \n",
    "6. Save the final mapped dataset as CSV.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29102303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libaries\n",
    "import re\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "import geopandas as gpd\n",
    "from rapidfuzz import process, fuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcf20fe",
   "metadata": {},
   "source": [
    "### Load sa2 and compute centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10d55579",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/59/n7t8nd2s08zcjsn4bd22nlsr0000gn/T/ipykernel_60874/2921337517.py:5: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  vic[\"Lat\"] = vic.geometry.centroid.y\n",
      "/var/folders/59/n7t8nd2s08zcjsn4bd22nlsr0000gn/T/ipykernel_60874/2921337517.py:6: UserWarning: Geometry is in a geographic CRS. Results from 'centroid' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  vic[\"Lng\"] = vic.geometry.centroid.x\n"
     ]
    }
   ],
   "source": [
    "shapefile = \"../../datasets/raw/district_shape/SA2_GDA2020_SHAPEFILE/SA2_2021_AUST_GDA2020.shp\"\n",
    "gdf = gpd.read_file(shapefile)\n",
    "vic = gdf[gdf[\"STE_CODE21\"] == \"2\"].copy()\n",
    "\n",
    "vic[\"Lat\"] = vic.geometry.centroid.y\n",
    "vic[\"Lng\"] = vic.geometry.centroid.x\n",
    "\n",
    "suburbs = {\n",
    "    row[\"SA2_NAME21\"]: (row[\"Lat\"], row[\"Lng\"])\n",
    "    for _, row in vic.iterrows()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f813569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename for consistency\n",
    "vic_out = vic[[\"SA2_NAME21\", \"Lat\", \"Lng\"]].rename(columns={\"SA2_NAME21\": \"Cluster\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7250f6",
   "metadata": {},
   "source": [
    "### Load cluster centroids and fuzzy matching preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d3ea484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning setup\n",
    "DIRECTIONALS = {\"north\", \"south\", \"east\", \"west\", \"upper\", \"lower\", \"central\", \"inner\", \"outer\"}\n",
    "STOP_TOKENS = DIRECTIONALS | {\"vic\", \"city\", \"road\", \"rd\"}\n",
    "\n",
    "def normalize_name(s: str) -> str:\n",
    "    s = s.lower()\n",
    "    s = re.sub(r\"\\(.*?\\)\", \"\", s)\n",
    "    s = s.replace(\"&\", \" and \")\n",
    "    s = re.sub(r\"[;/]\", \" \", s)\n",
    "    s = s.replace(\"–\", \" \").replace(\"-\", \" \")\n",
    "    s = re.sub(r\"\\bst\\.?\\b\", \"st\", s)\n",
    "    s = re.sub(r\"\\bmt\\.?\\b\", \"mount\", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def tokenize_base(s: str):\n",
    "    norm = normalize_name(s)\n",
    "    toks = [t for t in re.split(r\"[^a-z0-9]+\", norm) if t]\n",
    "    base_toks = [t for t in toks if t not in STOP_TOKENS]\n",
    "    primary = base_toks[0] if base_toks else (toks[0] if toks else None)\n",
    "    return norm, toks, base_toks, primary\n",
    "\n",
    "vic_out[\"cluster_norm\"] = vic_out[\"Cluster\"].apply(normalize_name)\n",
    "vic_out[\"tokens_all\"] = vic_out[\"cluster_norm\"].apply(lambda s: [t for t in re.split(r\"[^a-z0-9]+\", s) if t])\n",
    "vic_out[\"tokens_base\"] = vic_out[\"tokens_all\"].apply(lambda toks: [t for t in toks if t not in STOP_TOKENS])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e536a9d",
   "metadata": {},
   "source": [
    "### Match suburb name to the closest SA2 cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c81c6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_match(component: str):\n",
    "    \"\"\"\n",
    "    Find the best matching cluster in 'vic' for a given component name.\n",
    "\n",
    "    The function first checks for an exact match, then filters candidates\n",
    "    using primary and base tokens. If multiple candidates remain, it selects\n",
    "    the best one using fuzzy string matching.\n",
    "    \"\"\"\n",
    "    \n",
    "    comp_norm, comp_tokens, comp_base, comp_primary = tokenize_base(component)\n",
    "\n",
    "    # Exact match\n",
    "    exact = vic_out[vic_out[\"cluster_norm\"] == comp_norm]\n",
    "    if not exact.empty:\n",
    "        return exact.iloc[0]\n",
    "\n",
    "    # Filter primary token\n",
    "    if comp_primary:\n",
    "        cand = vic_out[vic_out[\"tokens_all\"].apply(lambda toks: comp_primary in toks)].copy()\n",
    "    else:\n",
    "        cand = vic_out.copy()\n",
    "\n",
    "    # Base token overlap\n",
    "    if comp_primary and len(comp_base) > 0:\n",
    "        cand[\"base_overlap\"] = cand[\"tokens_base\"].apply(lambda t: len(set(t) & set(comp_base)))\n",
    "        if cand[\"base_overlap\"].max() > 0:\n",
    "            cand = cand[cand[\"base_overlap\"] == cand[\"base_overlap\"].max()]\n",
    "\n",
    "    # Fuzzy match\n",
    "    if not cand.empty:\n",
    "        cand_strings = cand[\"cluster_norm\"].tolist()\n",
    "        match, score, idx = process.extractOne(comp_norm, cand_strings, scorer=fuzz.token_set_ratio)\n",
    "        return cand.iloc[idx]\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48de00c",
   "metadata": {},
   "source": [
    "### Function to map target suburb to cluster centroid via coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "128ebad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_target_suburb(target: str):\n",
    "    parts = [p.strip() for p in re.split(r\"\\s*-\\s*\", target) if p.strip()]\n",
    "    matches, coords = [], []\n",
    "\n",
    "    for comp in parts:\n",
    "        row = best_match(comp)\n",
    "        if row is not None and pd.notnull(row[\"Lat\"]) and pd.notnull(row[\"Lng\"]):\n",
    "            matches.append(row[\"Cluster\"])\n",
    "            coords.append((row[\"Lat\"], row[\"Lng\"]))\n",
    "\n",
    "    if not coords:\n",
    "        return None, None, None\n",
    "\n",
    "    lat = sum(c[0] for c in coords) / len(coords)\n",
    "    lng = sum(c[1] for c in coords) / len(coords)\n",
    "    return \"; \".join(matches), lat, lng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08eaf54",
   "metadata": {},
   "source": [
    "### Map all suburbs into clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1098c404",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_suburbs = [\n",
    "    \"Albert Park-Middle Park-West St Kilda\", \"Armadale\", \"Carlton North\", \"Carlton-Parkville\", \"CBD-St Kilda Rd\",\n",
    "    \"Collingwood-Abbotsford\", \"Docklands\", \"East Melbourne\", \"East St Kilda\", \"Elwood\", \"Fitzroy\",\n",
    "    \"Fitzroy North-Clifton Hill\", \"Flemington-Kensington\", \"North Melbourne-West Melbourne\", \"Port Melbourne\",\n",
    "    \"Prahran-Windsor\", \"Richmond-Burnley\", \"South Melbourne\", \"South Yarra\", \"Southbank\", \"St Kilda\", \"Toorak\",\n",
    "    \"Balwyn\", \"Blackburn\", \"Box Hill\", \"Bulleen-Templestowe-Doncaster\", \"Burwood-Ashburton\", \"Camberwell-Glen Iris\",\n",
    "    \"Canterbury-Surrey Hills-Mont Albert\", \"Chadstone-Oakleigh\", \"Clayton\", \"Doncaster East-Donvale\", \"East Hawthorn\",\n",
    "    \"Glen Waverley-Mulgrave\", \"Hawthorn\", \"Kew\", \"Mount Waverley\", \"Nunawading-Mitcham\",\n",
    "    \"Vermont-Forest Hill-Burwood East\", \"Aspendale-Chelsea-Carrum\", \"Bentleigh\", \"Brighton\", \"Brighton East\",\n",
    "    \"Carnegie\", \"Caulfield\", \"Cheltenham\", \"Elsternwick\", \"Hampton-Beaumaris\", \"Malvern\", \"Malvern East\",\n",
    "    \"Mentone-Parkdale-Mordialloc\", \"Murrumbeena-Hughesdale\", \"Altona\", \"Footscray\", \"Keilor East-Avondale Heights\",\n",
    "    \"Melton\", \"Newport-Spotswood\", \"St Albans-Deer Park\", \"Sunshine\", \"Sydenham\", \"Werribee-Hoppers Crossing\",\n",
    "    \"West Footscray\", \"Williamstown\", \"Yarraville-Seddon\", \"Broadmeadows-Roxburgh Park\", \"Brunswick\",\n",
    "    \"Coburg-Pascoe Vale South\", \"Craigieburn\", \"East Brunswick\", \"Essendon\", \"Gladstone Park-Tullamarine\", \"Keilor\",\n",
    "    \"Moonee Ponds-Ascot Vale\", \"Oak Park-Glenroy-Fawkner\", \"Pascoe Vale-Coburg North\", \"Sunbury\", \"West Brunswick\",\n",
    "    \"Bundoora-Greensborough-Hurstbridge\", \"Eltham-Research-Montmorency\", \"Fairfield-Alphington\",\n",
    "    \"Heidelberg-Heidelberg West\", \"Ivanhoe-Ivanhoe East\", \"Mill Park-Epping\", \"Northcote\", \"Preston\", \"Reservoir\",\n",
    "    \"Thomastown-Lalor\", \"Thornbury\", \"Whittlesea\", \"Bayswater\", \"Boronia\", \"Croydon-Lilydale\", \"Ferntree Gully\",\n",
    "    \"Ringwood\", \"Rowville\", \"Wantirna-Scoresby\", \"Yarra Ranges\", \"Berwick\", \"Cranbourne\", \"Dandenong\",\n",
    "    \"Dandenong North-Endeavour Hills\", \"Narre Warren-Hampton Park\", \"Noble Park\", \"Pakenham\", \"Springvale\",\n",
    "    \"Dromana-Portsea\", \"Frankston\", \"Hastings-Flinders\", \"Mt Eliza-Mornington-Mt Martha\", \"Seaford-Carrum Downs\",\n",
    "    \"Belmont-Grovedale\", \"Corio\", \"Geelong-Newcombe\", \"Herne Hill-Geelong West\", \"Lara\", \"Newtown\", \"North Geelong\",\n",
    "    \"Ballarat\", \"Mount Clear-Buninyong\", \"Sebastopol-Delacombe\", \"Wendouree-Alfredton\", \"Bendigo\",\n",
    "    \"Flora Hill-Bendigo East\", \"Golden Square-Kangaroo Flat\", \"North Bendigo\", \"Bairnsdale\", \"Benalla\", \"Castlemaine\",\n",
    "    \"Echuca\", \"Hamilton\", \"Horsham\", \"Mildura\", \"Moe-Newborough\", \"Morwell\", \"Ocean Grove-Barwon Heads\", \"Portland\",\n",
    "    \"Sale-Maffra\", \"Seymour\", \"Shepparton\", \"Swan Hill\", \"Torquay\", \"Traralgon\", \"Wanagaratta\", \"Warragul\",\n",
    "    \"Warrnambool\", \"Wodonga\",\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for t in target_suburbs:\n",
    "    matched, lat, lng = map_target_suburb(t)\n",
    "    rows.append({\"Target_Suburb\": t, \"Matched_Cluster\": matched, \"Lat\": lat, \"Lng\": lng})\n",
    "\n",
    "mapped_fixed = pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42a8efa",
   "metadata": {},
   "source": [
    "### Load sa2 and lga shapefiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf5842da",
   "metadata": {},
   "outputs": [],
   "source": [
    "sa2 = gpd.read_file(\"../../datasets/raw/district_shape/SA2_GDA2020_SHAPEFILE/SA2_2021_AUST_GDA2020.shp\")\n",
    "sa2_vic = sa2[sa2[\"STE_CODE21\"] == \"2\"].copy().to_crs(\"EPSG:4283\")\n",
    "\n",
    "lga = gpd.read_file(\"../../datasets/raw/district_shape/LGA_2021_AUST_GDA2020_SHP/LGA_2021_AUST_GDA2020.shp\")\n",
    "lga_vic = lga[lga[\"STE_CODE21\"] == \"2\"].copy().to_crs(\"EPSG:4283\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4481035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spatial join\n",
    "mapped_gdf = gpd.GeoDataFrame(mapped_fixed,geometry=[\n",
    "        Point(xy) if pd.notnull(xy[0]) and pd.notnull(xy[1]) else None\n",
    "        for xy in zip(mapped_fixed[\"Lng\"], mapped_fixed[\"Lat\"])\n",
    "    ],\n",
    "    crs=\"EPSG:4283\"\n",
    ")\n",
    "\n",
    "mapped_with_sa2 = gpd.sjoin(\n",
    "    mapped_gdf,\n",
    "    sa2_vic[[\"SA2_CODE21\", \"SA2_NAME21\", \"geometry\"]],\n",
    "    how=\"left\",\n",
    "    predicate=\"within\"\n",
    ")\n",
    "\n",
    "if \"index_right\" in mapped_with_sa2.columns:\n",
    "    mapped_with_sa2 = mapped_with_sa2.drop(columns=[\"index_right\"])\n",
    "\n",
    "mapped_with_both = gpd.sjoin(\n",
    "    mapped_with_sa2,\n",
    "    lga_vic[[\"LGA_CODE21\", \"LGA_NAME21\", \"geometry\"]],\n",
    "    how=\"left\",\n",
    "    predicate=\"within\"\n",
    ")\n",
    "\n",
    "mapped_with_both = mapped_with_both.drop(columns=[\"index_right\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c3fddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save \n",
    "output_path = (\"../../datasets/raw/mapped_target_suburbs.csv\")\n",
    "mapped_with_both.drop(columns=\"geometry\").to_csv(output_path, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
