{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ee97fd6",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fc28526",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "import pandas as pd\n",
    "DATA =  Path(\"..\") / \"datasets\" / \"VMFEAT\"# adjust if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8119c568",
   "metadata": {},
   "outputs": [],
   "source": [
    "foi_points = gpd.read_file(DATA / \"FOI_POINT.shp\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ffea1e",
   "metadata": {},
   "source": [
    "# Cleaning and preprocess for FOI POINTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21f4077d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_drop = [\n",
    "    \"UFI\", \"PFI\", \"FEATURE_ID\", \"PARENTFTID\",\n",
    "    \"SUPER_PFI\", \"CRDATE_PFI\", \"CRDATE_UFI\",\n",
    "    \"FEATURE_UF\", \"FEATURE_CR\", \"NAME_LABEL\",\n",
    "    \"PARENTNAME\", \"VICNMSTATC\" , \"CHILDEXIST\",\n",
    "    \"AUTHORGC\", \"AUTHORGID\", \"AUTHORGVER\",\n",
    "    \"VMADD_PFI\", \"VICNAMESID\" ,\"THEME1\",\"THEME2\",\n",
    "    \"FEATSTATUS\" \n",
    "]\n",
    "\n",
    "foi_points_clean = foi_points.drop(columns=[c for c in cols_to_drop if c in foi_points.columns])\n",
    "foi_points_clean = foi_points_clean[foi_points_clean[\"STATE\"].str.upper() == \"VIC\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c69e26",
   "metadata": {},
   "source": [
    "Map each FOI points to SA2 code and name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57974e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import MultiPoint\n",
    "def to_point(g):\n",
    "    return g.geoms[0] if isinstance(g, MultiPoint) and len(g.geoms) > 0 else g\n",
    "foi_points_clean[\"geometry\"] = foi_points_clean.geometry.apply(to_point)\n",
    "\n",
    "# Load ABS SA2 2021 polygons\n",
    "sa2 = gpd.read_file(DATA / \"SA2_2021_AUST_GDA2020.shp\")\n",
    "\n",
    "# Ensure CRS match\n",
    "foi_points_clean = foi_points_clean.to_crs(sa2.crs)\n",
    "\n",
    "# Spatial join: assign SA2 to each FOI\n",
    "foi_points_clean = gpd.sjoin(\n",
    "    foi_points_clean,\n",
    "    sa2[[\"SA2_CODE21\",\"SA2_NAME21\",\"geometry\"]],\n",
    "    how=\"left\",\n",
    "    predicate=\"intersects\"\n",
    ").drop(columns=[\"index_right\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39513af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeamanda/.local/lib/python3.10/site-packages/geopandas/array.py:408: UserWarning: Geometry is in a geographic CRS. Results from 'sjoin_nearest' are likely incorrect. Use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#For the points that is not within any boundary we put them to the closest point\n",
    "needs = foi_points_clean[\"SA2_CODE21\"].isna ()\n",
    "if needs.any():\n",
    "    sa2_pts = sa2.copy()\n",
    "    sa2_pts[\"geometry\"] = sa2_pts.geometry.representative_point()\n",
    "    fix = gpd.sjoin_nearest(\n",
    "        foi_points_clean.loc[needs, [\"geometry\"]],\n",
    "        sa2_pts[[\"SA2_CODE21\",\"SA2_NAME21\",\"geometry\"]],\n",
    "        how=\"left\",\n",
    "        distance_col=\"dist_to_sa2_m\"\n",
    "    )\n",
    "    foi_points_clean.loc[needs, [\"SA2_CODE21\",\"SA2_NAME21\"]] = fix[[\"SA2_CODE21\",\"SA2_NAME21\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb30a696",
   "metadata": {},
   "outputs": [],
   "source": [
    "foi_gdf = gpd.GeoDataFrame(\n",
    "    foi_points_clean,\n",
    "    geometry=\"geometry\",  # use the existing geometry column as-is\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "foi_gdf = foi_gdf.to_crs(epsg=3857)\n",
    "\n",
    "#Group the categories so that we can find the nearest distance\n",
    "#  school, hospital,entertainment, grocery stor, melbourne cbd/ melb central\n",
    "education =['primary school', 'secondary school', 'primary/secondary school','university']\n",
    "\n",
    "health = ['maternal/child health centre', 'community health centre', 'day procedure centre', 'disability support centre',\n",
    "          'general hospital', 'general hospital (emergency)',\n",
    "          'bush nursing hospital', 'ambulance station']\n",
    "\n",
    "tourist = ['tourist information centre', 'tourist attraction']\n",
    "\n",
    "cultural = ['church', 'mosque', 'monastry', 'vihara (buddhist)', 'mandir (hindu)']\n",
    "\n",
    "def assign_group(category):\n",
    "    if category in education:\n",
    "        return 'education'\n",
    "    elif category in health:\n",
    "        return 'health'\n",
    "    elif category in tourist:\n",
    "        return 'tourist'\n",
    "    elif category in cultural:\n",
    "        return 'cultural'\n",
    "    else:\n",
    "        return 'others'\n",
    "\n",
    "foi_gdf['group'] = foi_gdf['FEATSUBTYP'].apply(assign_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bfb801d",
   "metadata": {},
   "source": [
    "IMPORT DOMAIN DATASET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c39a140",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_df = pd.read_csv('/home/eeamanda/project-2-group-real-estate-industry-project-7-2025/datasets/domain_cleaned.csv')\n",
    "#Creating as geodataframe to read in the latitude and longitude \n",
    "domain_gdf = gpd.GeoDataFrame(\n",
    "    domain_df,\n",
    "    geometry=gpd.points_from_xy(domain_df.lon, domain_df.lat),\n",
    "    crs=\"EPSG:4326\"  # WGS84 (lat/lon)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cadd69",
   "metadata": {},
   "source": [
    "# CHECKING THE SHORTEST DISTANCE USING OPENROUTHREVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8d04f308",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "import openrouteservice\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# ORS client\n",
    "client = openrouteservice.Client(key=\"eyJvcmciOiI1YjNjZTM1OTc4NTExMTAwMDFjZjYyNDgiLCJpZCI6IjA2MzEyMjUyMzJhYjRiZDY4ZGFkZDY3MmVhZTc4MGYyIiwiaCI6Im11cm11cjY0In0=\") #Enter key in the \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634b7d40",
   "metadata": {},
   "source": [
    "# Calculating the distance and time for the nearest Schools and hospitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365c6f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import openrouteservice as ors\n",
    "from openrouteservice.exceptions import ApiError\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "WANTED_CATS = [\"education\", \"health\"]\n",
    "K_NEAREST = 3\n",
    "ORS_ELEMENTS_LIMIT = 3500          # sources × destinations per Matrix call\n",
    "BATCH_DELAY = 2                    # polite delay between API calls (seconds)\n",
    "OUTPUT_CSV = \"nearest_drive_metrics2.csv\"\n",
    "\n",
    "# =========================\n",
    "# UTILITIES\n",
    "# =========================\n",
    "def haversine_vec(orig_lons, orig_lats, dest_lons, dest_lats):\n",
    "    \"\"\"Return matrix of Haversine distances in meters, shape (n_origins, n_destinations).\"\"\"\n",
    "    R = 6371000.0\n",
    "    olon = np.radians(orig_lons)[:, None]\n",
    "    olat = np.radians(orig_lats)[:, None]\n",
    "    dlon = np.radians(dest_lons)[None, :]\n",
    "    dlat = np.radians(dest_lats)[None, :]\n",
    "    d_lon = dlon - olon\n",
    "    d_lat = dlat - olat\n",
    "    a = np.sin(d_lat/2.0)**2 + np.cos(olat) * np.cos(dlat) * np.sin(d_lon/2.0)**2\n",
    "    return 2.0 * R * np.arcsin(np.sqrt(a))\n",
    "\n",
    "def wait_until_matrix_metrics(origins, destinations):\n",
    "    \"\"\"\n",
    "    Call ORS Matrix for driving distance (meters) and duration (seconds).\n",
    "    Will WAIT/RETRY indefinitely until success. No fallback.\n",
    "    Returns: (dist_m, dur_s) as np.ndarrays shape (n_origins, n_destinations).\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            resp = client.distance_matrix(\n",
    "                locations=origins + destinations,\n",
    "                profile=\"driving-car\",\n",
    "                sources=list(range(len(origins))),\n",
    "                destinations=list(range(len(origins), len(origins) + len(destinations))),\n",
    "                metrics=[\"distance\", \"duration\"]\n",
    "            )\n",
    "            dist = np.array(resp[\"distances\"], dtype=float)\n",
    "            dur  = np.array(resp[\"durations\"], dtype=float)\n",
    "            return dist, dur\n",
    "\n",
    "        except ApiError as e:\n",
    "            msg = str(e)\n",
    "            # Backoff rules:\n",
    "            if \"Quota exceeded\" in msg or \"403\" in msg:\n",
    "                print(\"⚠️ ORS daily quota exceeded. Waiting 1 hour before retry...\")\n",
    "                time.sleep(60 * 60)\n",
    "            elif \"429\" in msg or \"Rate limit\" in msg:\n",
    "                print(\"⚠️ ORS rate limit hit. Waiting 10s before retry...\")\n",
    "                time.sleep(10)\n",
    "            else:\n",
    "                print(f\"⚠️ ORS error: {msg}. Waiting 5s before retry...\")\n",
    "                time.sleep(5)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Unexpected error: {e}. Waiting 10s before retry...\")\n",
    "            time.sleep(10)\n",
    "\n",
    "def split_gdf(gdf, chunk_size=30, start=0):\n",
    "    \"\"\"Yield chunks of a GeoDataFrame.\"\"\"\n",
    "    for i in range(start, len(gdf), chunk_size):\n",
    "        yield gdf.iloc[i:i+chunk_size].copy()\n",
    "\n",
    "# =========================\n",
    "# CORE\n",
    "# =========================\n",
    "def compute_nearest_drive_metrics_chunked(\n",
    "    domain_gdf: gpd.GeoDataFrame,\n",
    "    foi_gdf: gpd.GeoDataFrame,\n",
    "    output_csv: str = OUTPUT_CSV,\n",
    "    chunk_size: int = 30,\n",
    "    start_row: int = 7470,\n",
    "    limit_radius_m: float | None = None\n",
    "):\n",
    "    \"\"\"\n",
    "    For each domain row and each category:\n",
    "      - pick K nearest FOIs by straight-line (optionally within radius),\n",
    "      - dedupe FOIs across the chunk,\n",
    "      - call ORS Matrix (distance+duration) in safe batches (no fallback),\n",
    "      - store min driving distance (meters) and time (minutes):\n",
    "        nearest_{cat}_dist_m, nearest_{cat}_time_mins\n",
    "    \"\"\"\n",
    "    # Ensure WGS84 & lon/lat columns\n",
    "    domain = domain_gdf.to_crs(epsg=4326).copy()\n",
    "    foi = foi_gdf.to_crs(epsg=4326).copy()\n",
    "    foi = foi[foi[\"group\"].isin(WANTED_CATS)].copy()\n",
    "\n",
    "    for g in (domain, foi):\n",
    "        if \"lon\" not in g.columns or \"lat\" not in g.columns:\n",
    "            g[\"lon\"] = g.geometry.x\n",
    "            g[\"lat\"] = g.geometry.y\n",
    "\n",
    "    # Pre-split FOIs by category (coords only)\n",
    "    foi_by_cat = {}\n",
    "    for cat in WANTED_CATS:\n",
    "        sub = foi[foi[\"group\"] == cat].copy()\n",
    "        foi_by_cat[cat] = {\n",
    "            \"lon\": sub[\"lon\"].to_numpy(),\n",
    "            \"lat\": sub[\"lat\"].to_numpy()\n",
    "        }\n",
    "\n",
    "    # Fresh output\n",
    "    if os.path.exists(output_csv):\n",
    "        os.remove(output_csv)\n",
    "\n",
    "    for ch_i, chunk in enumerate(split_gdf(domain, chunk_size=chunk_size, start=start_row)):\n",
    "        print(f\"Processing chunk {ch_i+1} (rows {chunk.index.min()}–{chunk.index.max()}), size={len(chunk)}\")\n",
    "        o_lon = chunk[\"lon\"].to_numpy()\n",
    "        o_lat = chunk[\"lat\"].to_numpy()\n",
    "        n_o = len(chunk)\n",
    "\n",
    "        for cat in WANTED_CATS:\n",
    "            dest_lon = foi_by_cat[cat][\"lon\"]\n",
    "            dest_lat = foi_by_cat[cat][\"lat\"]\n",
    "\n",
    "            if dest_lon.size == 0:\n",
    "                chunk[f\"nearest_{cat}_dist_m\"] = np.full(n_o, np.nan)\n",
    "                chunk[f\"nearest_{cat}_time_mins\"] = np.full(n_o, np.nan)\n",
    "                continue\n",
    "\n",
    "            # 1) Top-K by Haversine per origin (optionally within radius)\n",
    "            dmat = haversine_vec(o_lon, o_lat, dest_lon, dest_lat)  # meters\n",
    "            if limit_radius_m is not None:\n",
    "                dmask = dmat.copy()\n",
    "                dmask[dmask > float(limit_radius_m)] = np.inf\n",
    "            else:\n",
    "                dmask = dmat\n",
    "\n",
    "            k = min(K_NEAREST, dmask.shape[1])\n",
    "            topk_idx = np.argpartition(dmask, kth=k-1, axis=1)[:, :k]\n",
    "            rows = np.arange(topk_idx.shape[0])[:, None]\n",
    "            topk_sorted = topk_idx[rows, np.argsort(dmask[rows, topk_idx])]\n",
    "\n",
    "            cand_sets = []\n",
    "            for r in range(n_o):\n",
    "                cands = [idx for idx in topk_sorted[r].tolist() if np.isfinite(dmask[r, idx])]\n",
    "                cand_sets.append(set(cands))\n",
    "\n",
    "            # 2) Deduplicate candidate destinations across the chunk\n",
    "            dest_unique = sorted(set().union(*cand_sets))\n",
    "            if len(dest_unique) == 0:\n",
    "                chunk[f\"nearest_{cat}_dist_m\"] = np.full(n_o, np.nan)\n",
    "                chunk[f\"nearest_{cat}_time_mins\"] = np.full(n_o, np.nan)\n",
    "                continue\n",
    "\n",
    "            dest_pos = {d: j for j, d in enumerate(dest_unique)}\n",
    "            dest_list = [(float(dest_lon[d]), float(dest_lat[d])) for d in dest_unique]\n",
    "\n",
    "            # 3) Matrix calls in element-safe batches\n",
    "            n_d = len(dest_list)\n",
    "            sources_per_call = max(1, ORS_ELEMENTS_LIMIT // n_d)\n",
    "\n",
    "            best_dist = np.full(n_o, np.nan, dtype=float)\n",
    "            best_time_s = np.full(n_o, np.nan, dtype=float)\n",
    "\n",
    "            start_idx = 0\n",
    "            while start_idx < n_o:\n",
    "                end_idx = min(n_o, start_idx + sources_per_call)\n",
    "                sub_origins = list(zip(o_lon[start_idx:end_idx], o_lat[start_idx:end_idx]))\n",
    "\n",
    "                # WAIT until ORS succeeds (no fallback)\n",
    "                dist_m, dur_s = wait_until_matrix_metrics(sub_origins, dest_list)\n",
    "\n",
    "                # For each origin in this sub-batch, only consider its own candidates\n",
    "                for local_r, global_r in enumerate(range(start_idx, end_idx)):\n",
    "                    cands = cand_sets[global_r]\n",
    "                    if not cands:\n",
    "                        continue\n",
    "                    cols = [dest_pos[d] for d in cands]\n",
    "\n",
    "                    # Distance\n",
    "                    vals_d = dist_m[local_r, cols]\n",
    "                    finite_d = vals_d[np.isfinite(vals_d)]\n",
    "                    if finite_d.size > 0:\n",
    "                        best_val_d = float(np.min(finite_d))\n",
    "                        if not np.isfinite(best_dist[global_r]) or best_val_d < best_dist[global_r]:\n",
    "                            best_dist[global_r] = best_val_d\n",
    "\n",
    "                    # Duration\n",
    "                    vals_t = dur_s[local_r, cols]\n",
    "                    finite_t = vals_t[np.isfinite(vals_t)]\n",
    "                    if finite_t.size > 0:\n",
    "                        best_val_t = float(np.min(finite_t))\n",
    "                        if not np.isfinite(best_time_s[global_r]) or best_val_t < best_time_s[global_r]:\n",
    "                            best_time_s[global_r] = best_val_t\n",
    "\n",
    "                time.sleep(BATCH_DELAY)\n",
    "                start_idx = end_idx\n",
    "\n",
    "            # 4) Write category result for this chunk\n",
    "            chunk[f\"nearest_{cat}_dist_m\"] = best_dist\n",
    "            chunk[f\"nearest_{cat}_time_mins\"] = (best_time_s / 60.0)  # seconds -> minutes\n",
    "\n",
    "        # Append chunk to CSV\n",
    "        chunk.to_csv(output_csv, index=False, mode=\"a\", header=(ch_i == 0))\n",
    "        print(f\"✅ Saved chunk {ch_i+1} -> {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b9af386a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1 (rows 7470–7499), size=30\n",
      "✅ Saved chunk 1 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 2 (rows 7500–7529), size=30\n",
      "✅ Saved chunk 2 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 3 (rows 7530–7559), size=30\n",
      "✅ Saved chunk 3 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 4 (rows 7560–7589), size=30\n",
      "✅ Saved chunk 4 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 5 (rows 7590–7619), size=30\n",
      "✅ Saved chunk 5 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 6 (rows 7620–7649), size=30\n",
      "✅ Saved chunk 6 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 7 (rows 7650–7679), size=30\n",
      "✅ Saved chunk 7 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 8 (rows 7680–7709), size=30\n",
      "✅ Saved chunk 8 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 9 (rows 7710–7739), size=30\n",
      "✅ Saved chunk 9 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 10 (rows 7740–7769), size=30\n",
      "✅ Saved chunk 10 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 11 (rows 7770–7799), size=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 1st time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved chunk 11 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 12 (rows 7800–7829), size=30\n",
      "✅ Saved chunk 12 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 13 (rows 7830–7859), size=30\n",
      "✅ Saved chunk 13 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 14 (rows 7860–7889), size=30\n",
      "✅ Saved chunk 14 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 15 (rows 7890–7919), size=30\n",
      "✅ Saved chunk 15 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 16 (rows 7920–7949), size=30\n",
      "✅ Saved chunk 16 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 17 (rows 7950–7979), size=30\n",
      "✅ Saved chunk 17 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 18 (rows 7980–8009), size=30\n",
      "✅ Saved chunk 18 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 19 (rows 8010–8039), size=30\n",
      "✅ Saved chunk 19 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 20 (rows 8040–8069), size=30\n",
      "✅ Saved chunk 20 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 21 (rows 8070–8099), size=30\n",
      "✅ Saved chunk 21 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 22 (rows 8100–8129), size=30\n",
      "✅ Saved chunk 22 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 23 (rows 8130–8159), size=30\n",
      "✅ Saved chunk 23 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 24 (rows 8160–8189), size=30\n",
      "✅ Saved chunk 24 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 25 (rows 8190–8219), size=30\n",
      "✅ Saved chunk 25 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 26 (rows 8220–8249), size=30\n",
      "✅ Saved chunk 26 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 27 (rows 8250–8279), size=30\n",
      "✅ Saved chunk 27 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 28 (rows 8280–8309), size=30\n",
      "✅ Saved chunk 28 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 29 (rows 8310–8339), size=30\n",
      "✅ Saved chunk 29 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 30 (rows 8340–8369), size=30\n",
      "✅ Saved chunk 30 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 31 (rows 8370–8399), size=30\n",
      "✅ Saved chunk 31 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 32 (rows 8400–8429), size=30\n",
      "✅ Saved chunk 32 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 33 (rows 8430–8459), size=30\n",
      "✅ Saved chunk 33 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 34 (rows 8460–8489), size=30\n",
      "✅ Saved chunk 34 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 35 (rows 8490–8519), size=30\n",
      "✅ Saved chunk 35 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 36 (rows 8520–8549), size=30\n",
      "✅ Saved chunk 36 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 37 (rows 8550–8579), size=30\n",
      "✅ Saved chunk 37 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 38 (rows 8580–8609), size=30\n",
      "✅ Saved chunk 38 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 39 (rows 8610–8639), size=30\n",
      "✅ Saved chunk 39 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 40 (rows 8640–8669), size=30\n",
      "✅ Saved chunk 40 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 41 (rows 8670–8699), size=30\n",
      "✅ Saved chunk 41 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 42 (rows 8700–8729), size=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 1st time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved chunk 42 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 43 (rows 8730–8759), size=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 1st time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n",
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 2nd time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved chunk 43 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 44 (rows 8760–8789), size=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 1st time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n",
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 2nd time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n",
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 3rd time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved chunk 44 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 45 (rows 8790–8819), size=30\n",
      "✅ Saved chunk 45 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 46 (rows 8820–8849), size=30\n",
      "✅ Saved chunk 46 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 47 (rows 8850–8879), size=30\n",
      "✅ Saved chunk 47 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 48 (rows 8880–8909), size=30\n",
      "✅ Saved chunk 48 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 49 (rows 8910–8939), size=30\n",
      "✅ Saved chunk 49 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 50 (rows 8940–8969), size=30\n",
      "✅ Saved chunk 50 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 51 (rows 8970–8999), size=30\n",
      "✅ Saved chunk 51 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 52 (rows 9000–9029), size=30\n",
      "✅ Saved chunk 52 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 53 (rows 9030–9059), size=30\n",
      "✅ Saved chunk 53 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 54 (rows 9060–9089), size=30\n",
      "✅ Saved chunk 54 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 55 (rows 9090–9119), size=30\n",
      "✅ Saved chunk 55 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 56 (rows 9120–9149), size=30\n",
      "✅ Saved chunk 56 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 57 (rows 9150–9179), size=30\n",
      "✅ Saved chunk 57 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 58 (rows 9180–9209), size=30\n",
      "✅ Saved chunk 58 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 59 (rows 9210–9239), size=30\n",
      "✅ Saved chunk 59 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 60 (rows 9240–9269), size=30\n",
      "✅ Saved chunk 60 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 61 (rows 9270–9299), size=30\n",
      "✅ Saved chunk 61 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 62 (rows 9300–9329), size=30\n",
      "✅ Saved chunk 62 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 63 (rows 9330–9359), size=30\n",
      "✅ Saved chunk 63 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 64 (rows 9360–9389), size=30\n",
      "✅ Saved chunk 64 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 65 (rows 9390–9419), size=30\n",
      "✅ Saved chunk 65 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 66 (rows 9420–9449), size=30\n",
      "✅ Saved chunk 66 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 67 (rows 9450–9479), size=30\n",
      "✅ Saved chunk 67 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 68 (rows 9480–9509), size=30\n",
      "✅ Saved chunk 68 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 69 (rows 9510–9539), size=30\n",
      "✅ Saved chunk 69 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 70 (rows 9540–9569), size=30\n",
      "✅ Saved chunk 70 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 71 (rows 9570–9599), size=30\n",
      "✅ Saved chunk 71 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 72 (rows 9600–9629), size=30\n",
      "✅ Saved chunk 72 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 73 (rows 9630–9659), size=30\n",
      "✅ Saved chunk 73 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 74 (rows 9660–9689), size=30\n",
      "✅ Saved chunk 74 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 75 (rows 9690–9719), size=30\n",
      "✅ Saved chunk 75 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 76 (rows 9720–9749), size=30\n",
      "✅ Saved chunk 76 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 77 (rows 9750–9779), size=30\n",
      "✅ Saved chunk 77 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 78 (rows 9780–9809), size=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 1st time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n",
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 2nd time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n",
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 3rd time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved chunk 78 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 79 (rows 9810–9839), size=30\n",
      "✅ Saved chunk 79 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 80 (rows 9840–9869), size=30\n",
      "✅ Saved chunk 80 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 81 (rows 9870–9899), size=30\n",
      "✅ Saved chunk 81 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 82 (rows 9900–9929), size=30\n",
      "✅ Saved chunk 82 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 83 (rows 9930–9959), size=30\n",
      "✅ Saved chunk 83 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 84 (rows 9960–9989), size=30\n",
      "✅ Saved chunk 84 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 85 (rows 9990–10019), size=30\n",
      "✅ Saved chunk 85 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 86 (rows 10020–10049), size=30\n",
      "✅ Saved chunk 86 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 87 (rows 10050–10079), size=30\n",
      "✅ Saved chunk 87 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 88 (rows 10080–10109), size=30\n",
      "✅ Saved chunk 88 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 89 (rows 10110–10139), size=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 1st time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved chunk 89 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 90 (rows 10140–10169), size=30\n",
      "✅ Saved chunk 90 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 91 (rows 10170–10199), size=30\n",
      "✅ Saved chunk 91 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 92 (rows 10200–10229), size=30\n",
      "✅ Saved chunk 92 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 93 (rows 10230–10259), size=30\n",
      "✅ Saved chunk 93 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 94 (rows 10260–10289), size=30\n",
      "✅ Saved chunk 94 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 95 (rows 10290–10319), size=30\n",
      "✅ Saved chunk 95 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 96 (rows 10320–10349), size=30\n",
      "✅ Saved chunk 96 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 97 (rows 10350–10379), size=30\n",
      "✅ Saved chunk 97 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 98 (rows 10380–10409), size=30\n",
      "✅ Saved chunk 98 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 99 (rows 10410–10439), size=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 1st time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n",
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 2nd time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved chunk 99 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 100 (rows 10440–10469), size=30\n",
      "✅ Saved chunk 100 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 101 (rows 10470–10499), size=30\n",
      "✅ Saved chunk 101 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 102 (rows 10500–10529), size=30\n",
      "✅ Saved chunk 102 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 103 (rows 10530–10559), size=30\n",
      "✅ Saved chunk 103 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 104 (rows 10560–10589), size=30\n",
      "✅ Saved chunk 104 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 105 (rows 10590–10619), size=30\n",
      "✅ Saved chunk 105 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 106 (rows 10620–10649), size=30\n",
      "✅ Saved chunk 106 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 107 (rows 10650–10679), size=30\n",
      "✅ Saved chunk 107 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 108 (rows 10680–10709), size=30\n",
      "✅ Saved chunk 108 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 109 (rows 10710–10739), size=30\n",
      "✅ Saved chunk 109 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 110 (rows 10740–10769), size=30\n",
      "✅ Saved chunk 110 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 111 (rows 10770–10799), size=30\n",
      "✅ Saved chunk 111 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 112 (rows 10800–10829), size=30\n",
      "✅ Saved chunk 112 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 113 (rows 10830–10859), size=30\n",
      "✅ Saved chunk 113 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 114 (rows 10860–10889), size=30\n",
      "✅ Saved chunk 114 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 115 (rows 10890–10919), size=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 1st time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved chunk 115 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 116 (rows 10920–10949), size=30\n",
      "✅ Saved chunk 116 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 117 (rows 10950–10979), size=30\n",
      "✅ Saved chunk 117 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 118 (rows 10980–11009), size=30\n",
      "✅ Saved chunk 118 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 119 (rows 11010–11039), size=30\n",
      "✅ Saved chunk 119 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 120 (rows 11040–11069), size=30\n",
      "✅ Saved chunk 120 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 121 (rows 11070–11099), size=30\n",
      "✅ Saved chunk 121 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 122 (rows 11100–11129), size=30\n",
      "✅ Saved chunk 122 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 123 (rows 11130–11159), size=30\n",
      "✅ Saved chunk 123 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 124 (rows 11160–11189), size=30\n",
      "✅ Saved chunk 124 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 125 (rows 11190–11219), size=30\n",
      "✅ Saved chunk 125 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 126 (rows 11220–11249), size=30\n",
      "✅ Saved chunk 126 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 127 (rows 11250–11279), size=30\n",
      "✅ Saved chunk 127 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 128 (rows 11280–11309), size=30\n",
      "✅ Saved chunk 128 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 129 (rows 11310–11339), size=30\n",
      "✅ Saved chunk 129 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 130 (rows 11340–11369), size=30\n",
      "✅ Saved chunk 130 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 131 (rows 11370–11399), size=30\n",
      "✅ Saved chunk 131 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 132 (rows 11400–11429), size=30\n",
      "✅ Saved chunk 132 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 133 (rows 11430–11459), size=30\n",
      "✅ Saved chunk 133 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 134 (rows 11460–11489), size=30\n",
      "✅ Saved chunk 134 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 135 (rows 11490–11519), size=30\n",
      "✅ Saved chunk 135 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 136 (rows 11520–11549), size=30\n",
      "✅ Saved chunk 136 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 137 (rows 11550–11579), size=30\n",
      "✅ Saved chunk 137 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 138 (rows 11580–11609), size=30\n",
      "✅ Saved chunk 138 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 139 (rows 11610–11639), size=30\n",
      "✅ Saved chunk 139 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 140 (rows 11640–11669), size=30\n",
      "✅ Saved chunk 140 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 141 (rows 11670–11699), size=30\n",
      "✅ Saved chunk 141 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 142 (rows 11700–11729), size=30\n",
      "✅ Saved chunk 142 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 143 (rows 11730–11759), size=30\n",
      "✅ Saved chunk 143 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 144 (rows 11760–11789), size=30\n",
      "✅ Saved chunk 144 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 145 (rows 11790–11819), size=30\n",
      "✅ Saved chunk 145 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 146 (rows 11820–11849), size=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 1st time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved chunk 146 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 147 (rows 11850–11879), size=30\n",
      "✅ Saved chunk 147 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 148 (rows 11880–11909), size=30\n",
      "✅ Saved chunk 148 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 149 (rows 11910–11939), size=30\n",
      "✅ Saved chunk 149 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 150 (rows 11940–11969), size=30\n",
      "✅ Saved chunk 150 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 151 (rows 11970–11999), size=30\n",
      "✅ Saved chunk 151 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 152 (rows 12000–12029), size=30\n",
      "✅ Saved chunk 152 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 153 (rows 12030–12059), size=30\n",
      "✅ Saved chunk 153 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 154 (rows 12060–12089), size=30\n",
      "✅ Saved chunk 154 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 155 (rows 12090–12119), size=30\n",
      "✅ Saved chunk 155 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 156 (rows 12120–12149), size=30\n",
      "✅ Saved chunk 156 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 157 (rows 12150–12179), size=30\n",
      "✅ Saved chunk 157 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 158 (rows 12180–12209), size=30\n",
      "✅ Saved chunk 158 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 159 (rows 12210–12239), size=30\n",
      "✅ Saved chunk 159 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 160 (rows 12240–12269), size=30\n",
      "✅ Saved chunk 160 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 161 (rows 12270–12299), size=30\n",
      "✅ Saved chunk 161 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 162 (rows 12300–12329), size=30\n",
      "✅ Saved chunk 162 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 163 (rows 12330–12359), size=30\n",
      "✅ Saved chunk 163 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 164 (rows 12360–12389), size=30\n",
      "✅ Saved chunk 164 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 165 (rows 12390–12419), size=30\n",
      "✅ Saved chunk 165 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 166 (rows 12420–12449), size=30\n",
      "✅ Saved chunk 166 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 167 (rows 12450–12479), size=30\n",
      "✅ Saved chunk 167 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 168 (rows 12480–12509), size=30\n",
      "✅ Saved chunk 168 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 169 (rows 12510–12539), size=30\n",
      "✅ Saved chunk 169 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 170 (rows 12540–12569), size=30\n",
      "✅ Saved chunk 170 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 171 (rows 12570–12599), size=30\n",
      "✅ Saved chunk 171 -> nearest_drive_metrics2.csv\n",
      "Processing chunk 172 (rows 12600–12617), size=18\n",
      "✅ Saved chunk 172 -> nearest_drive_metrics2.csv\n"
     ]
    }
   ],
   "source": [
    "compute_nearest_drive_metrics_chunked(\n",
    "    domain_gdf=domain_gdf,\n",
    "    foi_gdf=foi_gdf,\n",
    "    output_csv=\"nearest_drive_metrics2.csv\",\n",
    "    chunk_size=30,          # adjust to fit quota/limits\n",
    "    start_row=7470,            # e.g. resume from 0\n",
    "    limit_radius_m=15000    # optional cap (15 km straight-line for candidates)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a013b1",
   "metadata": {},
   "source": [
    "# Calculating the drive time and distance to the CBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a30263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import openrouteservice as ors\n",
    "from openrouteservice.exceptions import ApiError\n",
    "\n",
    "# =========================\n",
    "# CONFIG\n",
    "# =========================\n",
    "CBD_COORD = (144.9671, -37.8183)   # Melbourne CBD (lon, lat)\n",
    "ORS_ELEMENTS_LIMIT = 3500\n",
    "BATCH_DELAY = 2\n",
    "OUTPUT_CSV = \"domain_to_cbd.csv\"\n",
    "\n",
    "# =========================\n",
    "# UTILITIES\n",
    "# =========================\n",
    "def wait_until_matrix_metrics(origins, destinations):\n",
    "    \"\"\"\n",
    "    Call ORS Matrix for driving distance (meters) and duration (seconds).\n",
    "    Will retry indefinitely until success.\n",
    "    Returns: (dist_m, dur_s)\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            resp = client.distance_matrix(\n",
    "                locations=origins + destinations,\n",
    "                profile=\"driving-car\",\n",
    "                sources=list(range(len(origins))),\n",
    "                destinations=list(range(len(origins), len(origins) + len(destinations))),\n",
    "                metrics=[\"distance\", \"duration\"]\n",
    "            )\n",
    "            dist = np.array(resp[\"distances\"], dtype=float)\n",
    "            dur  = np.array(resp[\"durations\"], dtype=float)\n",
    "            return dist, dur\n",
    "        except ApiError as e:\n",
    "            msg = str(e)\n",
    "            if \"Quota exceeded\" in msg or \"403\" in msg:\n",
    "                print(\"⚠️ ORS daily quota exceeded. Waiting 1 hour...\")\n",
    "                time.sleep(60 * 60)\n",
    "            elif \"429\" in msg or \"Rate limit\" in msg:\n",
    "                print(\"⚠️ ORS rate limit hit. Waiting 10s...\")\n",
    "                time.sleep(10)\n",
    "            else:\n",
    "                print(f\"⚠️ ORS error: {msg}. Retrying in 5s...\")\n",
    "                time.sleep(5)\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Unexpected error: {e}. Waiting 10s...\")\n",
    "            time.sleep(10)\n",
    "\n",
    "def split_gdf(gdf, chunk_size=30, start=0):\n",
    "    \"\"\"Yield chunks of a GeoDataFrame.\"\"\"\n",
    "    for i in range(start, len(gdf), chunk_size):\n",
    "        yield gdf.iloc[i:i+chunk_size].copy()\n",
    "\n",
    "# =========================\n",
    "# CORE\n",
    "# =========================\n",
    "def compute_domain_to_cbd(\n",
    "    domain_gdf: gpd.GeoDataFrame,\n",
    "    output_csv: str = OUTPUT_CSV,\n",
    "    chunk_size: int = 30,\n",
    "    start_row: int = 0\n",
    "):\n",
    "    \"\"\"\n",
    "    For each domain row, compute driving distance (m) and time (mins)\n",
    "    from domain location to Melbourne CBD.\n",
    "    \"\"\"\n",
    "    domain = domain_gdf.to_crs(epsg=4326).copy()\n",
    "\n",
    "    if \"lon\" not in domain.columns or \"lat\" not in domain.columns:\n",
    "        domain[\"lon\"] = domain.geometry.x\n",
    "        domain[\"lat\"] = domain.geometry.y\n",
    "\n",
    "    if os.path.exists(output_csv):\n",
    "        os.remove(output_csv)\n",
    "\n",
    "    dest_list = [CBD_COORD]\n",
    "\n",
    "    for ch_i, chunk in enumerate(split_gdf(domain, chunk_size=chunk_size, start=start_row)):\n",
    "        print(f\"Processing chunk {ch_i+1} (rows {chunk.index.min()}–{chunk.index.max()}), size={len(chunk)}\")\n",
    "\n",
    "        o_lon = chunk[\"lon\"].to_numpy()\n",
    "        o_lat = chunk[\"lat\"].to_numpy()\n",
    "        n_o = len(chunk)\n",
    "\n",
    "        best_dist = np.full(n_o, np.nan, dtype=float)\n",
    "        best_time_s = np.full(n_o, np.nan, dtype=float)\n",
    "\n",
    "        # batch calls\n",
    "        sources_per_call = max(1, ORS_ELEMENTS_LIMIT // len(dest_list))\n",
    "        start_idx = 0\n",
    "        while start_idx < n_o:\n",
    "            end_idx = min(n_o, start_idx + sources_per_call)\n",
    "            sub_origins = list(zip(o_lon[start_idx:end_idx], o_lat[start_idx:end_idx]))\n",
    "\n",
    "            dist_m, dur_s = wait_until_matrix_metrics(sub_origins, dest_list)\n",
    "\n",
    "            for local_r, global_r in enumerate(range(start_idx, end_idx)):\n",
    "                best_dist[global_r] = float(dist_m[local_r, 0])\n",
    "                best_time_s[global_r] = float(dur_s[local_r, 0])\n",
    "\n",
    "            time.sleep(BATCH_DELAY)\n",
    "            start_idx = end_idx\n",
    "\n",
    "        chunk[\"cbd_dist_m\"] = best_dist\n",
    "        chunk[\"cbd_time_mins\"] = (best_time_s / 60.0)\n",
    "\n",
    "        # Append to CSV\n",
    "        chunk.to_csv(output_csv, index=False, mode=\"a\", header=(ch_i == 0))\n",
    "        print(f\"✅ Saved chunk {ch_i+1} -> {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dbdd746c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing chunk 1 (rows 0–29), size=30\n",
      "✅ Saved chunk 1 -> domain_to_cbd.csv\n",
      "Processing chunk 2 (rows 30–59), size=30\n",
      "✅ Saved chunk 2 -> domain_to_cbd.csv\n",
      "Processing chunk 3 (rows 60–89), size=30\n",
      "✅ Saved chunk 3 -> domain_to_cbd.csv\n",
      "Processing chunk 4 (rows 90–119), size=30\n",
      "✅ Saved chunk 4 -> domain_to_cbd.csv\n",
      "Processing chunk 5 (rows 120–149), size=30\n",
      "✅ Saved chunk 5 -> domain_to_cbd.csv\n",
      "Processing chunk 6 (rows 150–179), size=30\n",
      "✅ Saved chunk 6 -> domain_to_cbd.csv\n",
      "Processing chunk 7 (rows 180–209), size=30\n",
      "✅ Saved chunk 7 -> domain_to_cbd.csv\n",
      "Processing chunk 8 (rows 210–239), size=30\n",
      "✅ Saved chunk 8 -> domain_to_cbd.csv\n",
      "Processing chunk 9 (rows 240–269), size=30\n",
      "✅ Saved chunk 9 -> domain_to_cbd.csv\n",
      "Processing chunk 10 (rows 270–299), size=30\n",
      "✅ Saved chunk 10 -> domain_to_cbd.csv\n",
      "Processing chunk 11 (rows 300–329), size=30\n",
      "✅ Saved chunk 11 -> domain_to_cbd.csv\n",
      "Processing chunk 12 (rows 330–359), size=30\n",
      "✅ Saved chunk 12 -> domain_to_cbd.csv\n",
      "Processing chunk 13 (rows 360–389), size=30\n",
      "✅ Saved chunk 13 -> domain_to_cbd.csv\n",
      "Processing chunk 14 (rows 390–419), size=30\n",
      "✅ Saved chunk 14 -> domain_to_cbd.csv\n",
      "Processing chunk 15 (rows 420–449), size=30\n",
      "✅ Saved chunk 15 -> domain_to_cbd.csv\n",
      "Processing chunk 16 (rows 450–479), size=30\n",
      "✅ Saved chunk 16 -> domain_to_cbd.csv\n",
      "Processing chunk 17 (rows 480–509), size=30\n",
      "✅ Saved chunk 17 -> domain_to_cbd.csv\n",
      "Processing chunk 18 (rows 510–539), size=30\n",
      "✅ Saved chunk 18 -> domain_to_cbd.csv\n",
      "Processing chunk 19 (rows 540–569), size=30\n",
      "✅ Saved chunk 19 -> domain_to_cbd.csv\n",
      "Processing chunk 20 (rows 570–599), size=30\n",
      "✅ Saved chunk 20 -> domain_to_cbd.csv\n",
      "Processing chunk 21 (rows 600–629), size=30\n",
      "✅ Saved chunk 21 -> domain_to_cbd.csv\n",
      "Processing chunk 22 (rows 630–659), size=30\n",
      "✅ Saved chunk 22 -> domain_to_cbd.csv\n",
      "Processing chunk 23 (rows 660–689), size=30\n",
      "✅ Saved chunk 23 -> domain_to_cbd.csv\n",
      "Processing chunk 24 (rows 690–719), size=30\n",
      "✅ Saved chunk 24 -> domain_to_cbd.csv\n",
      "Processing chunk 25 (rows 720–749), size=30\n",
      "✅ Saved chunk 25 -> domain_to_cbd.csv\n",
      "Processing chunk 26 (rows 750–779), size=30\n",
      "✅ Saved chunk 26 -> domain_to_cbd.csv\n",
      "Processing chunk 27 (rows 780–809), size=30\n",
      "✅ Saved chunk 27 -> domain_to_cbd.csv\n",
      "Processing chunk 28 (rows 810–839), size=30\n",
      "✅ Saved chunk 28 -> domain_to_cbd.csv\n",
      "Processing chunk 29 (rows 840–869), size=30\n",
      "✅ Saved chunk 29 -> domain_to_cbd.csv\n",
      "Processing chunk 30 (rows 870–899), size=30\n",
      "✅ Saved chunk 30 -> domain_to_cbd.csv\n",
      "Processing chunk 31 (rows 900–929), size=30\n",
      "✅ Saved chunk 31 -> domain_to_cbd.csv\n",
      "Processing chunk 32 (rows 930–959), size=30\n",
      "✅ Saved chunk 32 -> domain_to_cbd.csv\n",
      "Processing chunk 33 (rows 960–989), size=30\n",
      "✅ Saved chunk 33 -> domain_to_cbd.csv\n",
      "Processing chunk 34 (rows 990–1019), size=30\n",
      "✅ Saved chunk 34 -> domain_to_cbd.csv\n",
      "Processing chunk 35 (rows 1020–1049), size=30\n",
      "✅ Saved chunk 35 -> domain_to_cbd.csv\n",
      "Processing chunk 36 (rows 1050–1079), size=30\n",
      "✅ Saved chunk 36 -> domain_to_cbd.csv\n",
      "Processing chunk 37 (rows 1080–1109), size=30\n",
      "✅ Saved chunk 37 -> domain_to_cbd.csv\n",
      "Processing chunk 38 (rows 1110–1139), size=30\n",
      "✅ Saved chunk 38 -> domain_to_cbd.csv\n",
      "Processing chunk 39 (rows 1140–1169), size=30\n",
      "✅ Saved chunk 39 -> domain_to_cbd.csv\n",
      "Processing chunk 40 (rows 1170–1199), size=30\n",
      "✅ Saved chunk 40 -> domain_to_cbd.csv\n",
      "Processing chunk 41 (rows 1200–1229), size=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 1st time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n",
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 2nd time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n",
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 3rd time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n",
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 4th time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n",
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 5th time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved chunk 41 -> domain_to_cbd.csv\n",
      "Processing chunk 42 (rows 1230–1259), size=30\n",
      "✅ Saved chunk 42 -> domain_to_cbd.csv\n",
      "Processing chunk 43 (rows 1260–1289), size=30\n",
      "✅ Saved chunk 43 -> domain_to_cbd.csv\n",
      "Processing chunk 44 (rows 1290–1319), size=30\n",
      "✅ Saved chunk 44 -> domain_to_cbd.csv\n",
      "Processing chunk 45 (rows 1320–1349), size=30\n",
      "✅ Saved chunk 45 -> domain_to_cbd.csv\n",
      "Processing chunk 46 (rows 1350–1379), size=30\n",
      "✅ Saved chunk 46 -> domain_to_cbd.csv\n",
      "Processing chunk 47 (rows 1380–1409), size=30\n",
      "✅ Saved chunk 47 -> domain_to_cbd.csv\n",
      "Processing chunk 48 (rows 1410–1439), size=30\n",
      "✅ Saved chunk 48 -> domain_to_cbd.csv\n",
      "Processing chunk 49 (rows 1440–1469), size=30\n",
      "✅ Saved chunk 49 -> domain_to_cbd.csv\n",
      "Processing chunk 50 (rows 1470–1499), size=30\n",
      "✅ Saved chunk 50 -> domain_to_cbd.csv\n",
      "Processing chunk 51 (rows 1500–1529), size=30\n",
      "✅ Saved chunk 51 -> domain_to_cbd.csv\n",
      "Processing chunk 52 (rows 1530–1559), size=30\n",
      "✅ Saved chunk 52 -> domain_to_cbd.csv\n",
      "Processing chunk 53 (rows 1560–1589), size=30\n",
      "✅ Saved chunk 53 -> domain_to_cbd.csv\n",
      "Processing chunk 54 (rows 1590–1619), size=30\n",
      "✅ Saved chunk 54 -> domain_to_cbd.csv\n",
      "Processing chunk 55 (rows 1620–1649), size=30\n",
      "✅ Saved chunk 55 -> domain_to_cbd.csv\n",
      "Processing chunk 56 (rows 1650–1679), size=30\n",
      "✅ Saved chunk 56 -> domain_to_cbd.csv\n",
      "Processing chunk 57 (rows 1680–1709), size=30\n",
      "✅ Saved chunk 57 -> domain_to_cbd.csv\n",
      "Processing chunk 58 (rows 1710–1739), size=30\n",
      "✅ Saved chunk 58 -> domain_to_cbd.csv\n",
      "Processing chunk 59 (rows 1740–1769), size=30\n",
      "✅ Saved chunk 59 -> domain_to_cbd.csv\n",
      "Processing chunk 60 (rows 1770–1799), size=30\n",
      "✅ Saved chunk 60 -> domain_to_cbd.csv\n",
      "Processing chunk 61 (rows 1800–1829), size=30\n",
      "✅ Saved chunk 61 -> domain_to_cbd.csv\n",
      "Processing chunk 62 (rows 1830–1859), size=30\n",
      "✅ Saved chunk 62 -> domain_to_cbd.csv\n",
      "Processing chunk 63 (rows 1860–1889), size=30\n",
      "✅ Saved chunk 63 -> domain_to_cbd.csv\n",
      "Processing chunk 64 (rows 1890–1919), size=30\n",
      "✅ Saved chunk 64 -> domain_to_cbd.csv\n",
      "Processing chunk 65 (rows 1920–1949), size=30\n",
      "✅ Saved chunk 65 -> domain_to_cbd.csv\n",
      "Processing chunk 66 (rows 1950–1979), size=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 1st time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved chunk 66 -> domain_to_cbd.csv\n",
      "Processing chunk 67 (rows 1980–2009), size=30\n",
      "✅ Saved chunk 67 -> domain_to_cbd.csv\n",
      "Processing chunk 68 (rows 2010–2039), size=30\n",
      "✅ Saved chunk 68 -> domain_to_cbd.csv\n",
      "Processing chunk 69 (rows 2040–2069), size=30\n",
      "✅ Saved chunk 69 -> domain_to_cbd.csv\n",
      "Processing chunk 70 (rows 2070–2099), size=30\n",
      "✅ Saved chunk 70 -> domain_to_cbd.csv\n",
      "Processing chunk 71 (rows 2100–2129), size=30\n",
      "✅ Saved chunk 71 -> domain_to_cbd.csv\n",
      "Processing chunk 72 (rows 2130–2159), size=30\n",
      "✅ Saved chunk 72 -> domain_to_cbd.csv\n",
      "Processing chunk 73 (rows 2160–2189), size=30\n",
      "✅ Saved chunk 73 -> domain_to_cbd.csv\n",
      "Processing chunk 74 (rows 2190–2219), size=30\n",
      "✅ Saved chunk 74 -> domain_to_cbd.csv\n",
      "Processing chunk 75 (rows 2220–2249), size=30\n",
      "✅ Saved chunk 75 -> domain_to_cbd.csv\n",
      "Processing chunk 76 (rows 2250–2279), size=30\n",
      "✅ Saved chunk 76 -> domain_to_cbd.csv\n",
      "Processing chunk 77 (rows 2280–2309), size=30\n",
      "✅ Saved chunk 77 -> domain_to_cbd.csv\n",
      "Processing chunk 78 (rows 2310–2339), size=30\n",
      "✅ Saved chunk 78 -> domain_to_cbd.csv\n",
      "Processing chunk 79 (rows 2340–2369), size=30\n",
      "✅ Saved chunk 79 -> domain_to_cbd.csv\n",
      "Processing chunk 80 (rows 2370–2399), size=30\n",
      "✅ Saved chunk 80 -> domain_to_cbd.csv\n",
      "Processing chunk 81 (rows 2400–2429), size=30\n",
      "✅ Saved chunk 81 -> domain_to_cbd.csv\n",
      "Processing chunk 82 (rows 2430–2459), size=30\n",
      "✅ Saved chunk 82 -> domain_to_cbd.csv\n",
      "Processing chunk 83 (rows 2460–2489), size=30\n",
      "✅ Saved chunk 83 -> domain_to_cbd.csv\n",
      "Processing chunk 84 (rows 2490–2519), size=30\n",
      "✅ Saved chunk 84 -> domain_to_cbd.csv\n",
      "Processing chunk 85 (rows 2520–2549), size=30\n",
      "✅ Saved chunk 85 -> domain_to_cbd.csv\n",
      "Processing chunk 86 (rows 2550–2579), size=30\n",
      "✅ Saved chunk 86 -> domain_to_cbd.csv\n",
      "Processing chunk 87 (rows 2580–2609), size=30\n",
      "✅ Saved chunk 87 -> domain_to_cbd.csv\n",
      "Processing chunk 88 (rows 2610–2639), size=30\n",
      "✅ Saved chunk 88 -> domain_to_cbd.csv\n",
      "Processing chunk 89 (rows 2640–2669), size=30\n",
      "✅ Saved chunk 89 -> domain_to_cbd.csv\n",
      "Processing chunk 90 (rows 2670–2699), size=30\n",
      "✅ Saved chunk 90 -> domain_to_cbd.csv\n",
      "Processing chunk 91 (rows 2700–2729), size=30\n",
      "✅ Saved chunk 91 -> domain_to_cbd.csv\n",
      "Processing chunk 92 (rows 2730–2759), size=30\n",
      "✅ Saved chunk 92 -> domain_to_cbd.csv\n",
      "Processing chunk 93 (rows 2760–2789), size=30\n",
      "✅ Saved chunk 93 -> domain_to_cbd.csv\n",
      "Processing chunk 94 (rows 2790–2819), size=30\n",
      "✅ Saved chunk 94 -> domain_to_cbd.csv\n",
      "Processing chunk 95 (rows 2820–2849), size=30\n",
      "✅ Saved chunk 95 -> domain_to_cbd.csv\n",
      "Processing chunk 96 (rows 2850–2879), size=30\n",
      "✅ Saved chunk 96 -> domain_to_cbd.csv\n",
      "Processing chunk 97 (rows 2880–2909), size=30\n",
      "✅ Saved chunk 97 -> domain_to_cbd.csv\n",
      "Processing chunk 98 (rows 2910–2939), size=30\n",
      "✅ Saved chunk 98 -> domain_to_cbd.csv\n",
      "Processing chunk 99 (rows 2940–2969), size=30\n",
      "✅ Saved chunk 99 -> domain_to_cbd.csv\n",
      "Processing chunk 100 (rows 2970–2999), size=30\n",
      "✅ Saved chunk 100 -> domain_to_cbd.csv\n",
      "Processing chunk 101 (rows 3000–3029), size=30\n",
      "✅ Saved chunk 101 -> domain_to_cbd.csv\n",
      "Processing chunk 102 (rows 3030–3059), size=30\n",
      "✅ Saved chunk 102 -> domain_to_cbd.csv\n",
      "Processing chunk 103 (rows 3060–3089), size=30\n",
      "✅ Saved chunk 103 -> domain_to_cbd.csv\n",
      "Processing chunk 104 (rows 3090–3119), size=30\n",
      "✅ Saved chunk 104 -> domain_to_cbd.csv\n",
      "Processing chunk 105 (rows 3120–3149), size=30\n",
      "✅ Saved chunk 105 -> domain_to_cbd.csv\n",
      "Processing chunk 106 (rows 3150–3179), size=30\n",
      "✅ Saved chunk 106 -> domain_to_cbd.csv\n",
      "Processing chunk 107 (rows 3180–3209), size=30\n",
      "✅ Saved chunk 107 -> domain_to_cbd.csv\n",
      "Processing chunk 108 (rows 3210–3239), size=30\n",
      "✅ Saved chunk 108 -> domain_to_cbd.csv\n",
      "Processing chunk 109 (rows 3240–3269), size=30\n",
      "✅ Saved chunk 109 -> domain_to_cbd.csv\n",
      "Processing chunk 110 (rows 3270–3299), size=30\n",
      "✅ Saved chunk 110 -> domain_to_cbd.csv\n",
      "Processing chunk 111 (rows 3300–3329), size=30\n",
      "✅ Saved chunk 111 -> domain_to_cbd.csv\n",
      "Processing chunk 112 (rows 3330–3359), size=30\n",
      "✅ Saved chunk 112 -> domain_to_cbd.csv\n",
      "Processing chunk 113 (rows 3360–3389), size=30\n",
      "✅ Saved chunk 113 -> domain_to_cbd.csv\n",
      "Processing chunk 114 (rows 3390–3419), size=30\n",
      "✅ Saved chunk 114 -> domain_to_cbd.csv\n",
      "Processing chunk 115 (rows 3420–3449), size=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 1st time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n",
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 2nd time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved chunk 115 -> domain_to_cbd.csv\n",
      "Processing chunk 116 (rows 3450–3479), size=30\n",
      "✅ Saved chunk 116 -> domain_to_cbd.csv\n",
      "Processing chunk 117 (rows 3480–3509), size=30\n",
      "✅ Saved chunk 117 -> domain_to_cbd.csv\n",
      "Processing chunk 118 (rows 3510–3539), size=30\n",
      "✅ Saved chunk 118 -> domain_to_cbd.csv\n",
      "Processing chunk 119 (rows 3540–3569), size=30\n",
      "✅ Saved chunk 119 -> domain_to_cbd.csv\n",
      "Processing chunk 120 (rows 3570–3599), size=30\n",
      "✅ Saved chunk 120 -> domain_to_cbd.csv\n",
      "Processing chunk 121 (rows 3600–3629), size=30\n",
      "✅ Saved chunk 121 -> domain_to_cbd.csv\n",
      "Processing chunk 122 (rows 3630–3659), size=30\n",
      "✅ Saved chunk 122 -> domain_to_cbd.csv\n",
      "Processing chunk 123 (rows 3660–3689), size=30\n",
      "✅ Saved chunk 123 -> domain_to_cbd.csv\n",
      "Processing chunk 124 (rows 3690–3719), size=30\n",
      "✅ Saved chunk 124 -> domain_to_cbd.csv\n",
      "Processing chunk 125 (rows 3720–3749), size=30\n",
      "✅ Saved chunk 125 -> domain_to_cbd.csv\n",
      "Processing chunk 126 (rows 3750–3779), size=30\n",
      "✅ Saved chunk 126 -> domain_to_cbd.csv\n",
      "Processing chunk 127 (rows 3780–3809), size=30\n",
      "✅ Saved chunk 127 -> domain_to_cbd.csv\n",
      "Processing chunk 128 (rows 3810–3839), size=30\n",
      "✅ Saved chunk 128 -> domain_to_cbd.csv\n",
      "Processing chunk 129 (rows 3840–3869), size=30\n",
      "✅ Saved chunk 129 -> domain_to_cbd.csv\n",
      "Processing chunk 130 (rows 3870–3899), size=30\n",
      "✅ Saved chunk 130 -> domain_to_cbd.csv\n",
      "Processing chunk 131 (rows 3900–3929), size=30\n",
      "✅ Saved chunk 131 -> domain_to_cbd.csv\n",
      "Processing chunk 132 (rows 3930–3959), size=30\n",
      "✅ Saved chunk 132 -> domain_to_cbd.csv\n",
      "Processing chunk 133 (rows 3960–3989), size=30\n",
      "✅ Saved chunk 133 -> domain_to_cbd.csv\n",
      "Processing chunk 134 (rows 3990–4019), size=30\n",
      "✅ Saved chunk 134 -> domain_to_cbd.csv\n",
      "Processing chunk 135 (rows 4020–4049), size=30\n",
      "✅ Saved chunk 135 -> domain_to_cbd.csv\n",
      "Processing chunk 136 (rows 4050–4079), size=30\n",
      "✅ Saved chunk 136 -> domain_to_cbd.csv\n",
      "Processing chunk 137 (rows 4080–4109), size=30\n",
      "✅ Saved chunk 137 -> domain_to_cbd.csv\n",
      "Processing chunk 138 (rows 4110–4139), size=30\n",
      "✅ Saved chunk 138 -> domain_to_cbd.csv\n",
      "Processing chunk 139 (rows 4140–4169), size=30\n",
      "✅ Saved chunk 139 -> domain_to_cbd.csv\n",
      "Processing chunk 140 (rows 4170–4199), size=30\n",
      "✅ Saved chunk 140 -> domain_to_cbd.csv\n",
      "Processing chunk 141 (rows 4200–4229), size=30\n",
      "✅ Saved chunk 141 -> domain_to_cbd.csv\n",
      "Processing chunk 142 (rows 4230–4259), size=30\n",
      "✅ Saved chunk 142 -> domain_to_cbd.csv\n",
      "Processing chunk 143 (rows 4260–4289), size=30\n",
      "✅ Saved chunk 143 -> domain_to_cbd.csv\n",
      "Processing chunk 144 (rows 4290–4319), size=30\n",
      "✅ Saved chunk 144 -> domain_to_cbd.csv\n",
      "Processing chunk 145 (rows 4320–4349), size=30\n",
      "✅ Saved chunk 145 -> domain_to_cbd.csv\n",
      "Processing chunk 146 (rows 4350–4379), size=30\n",
      "✅ Saved chunk 146 -> domain_to_cbd.csv\n",
      "Processing chunk 147 (rows 4380–4409), size=30\n",
      "✅ Saved chunk 147 -> domain_to_cbd.csv\n",
      "Processing chunk 148 (rows 4410–4439), size=30\n",
      "✅ Saved chunk 148 -> domain_to_cbd.csv\n",
      "Processing chunk 149 (rows 4440–4469), size=30\n",
      "✅ Saved chunk 149 -> domain_to_cbd.csv\n",
      "Processing chunk 150 (rows 4470–4499), size=30\n",
      "✅ Saved chunk 150 -> domain_to_cbd.csv\n",
      "Processing chunk 151 (rows 4500–4529), size=30\n",
      "✅ Saved chunk 151 -> domain_to_cbd.csv\n",
      "Processing chunk 152 (rows 4530–4559), size=30\n",
      "✅ Saved chunk 152 -> domain_to_cbd.csv\n",
      "Processing chunk 153 (rows 4560–4589), size=30\n",
      "✅ Saved chunk 153 -> domain_to_cbd.csv\n",
      "Processing chunk 154 (rows 4590–4619), size=30\n",
      "✅ Saved chunk 154 -> domain_to_cbd.csv\n",
      "Processing chunk 155 (rows 4620–4649), size=30\n",
      "✅ Saved chunk 155 -> domain_to_cbd.csv\n",
      "Processing chunk 156 (rows 4650–4679), size=30\n",
      "✅ Saved chunk 156 -> domain_to_cbd.csv\n",
      "Processing chunk 157 (rows 4680–4709), size=30\n",
      "✅ Saved chunk 157 -> domain_to_cbd.csv\n",
      "Processing chunk 158 (rows 4710–4739), size=30\n",
      "✅ Saved chunk 158 -> domain_to_cbd.csv\n",
      "Processing chunk 159 (rows 4740–4769), size=30\n",
      "✅ Saved chunk 159 -> domain_to_cbd.csv\n",
      "Processing chunk 160 (rows 4770–4799), size=30\n",
      "✅ Saved chunk 160 -> domain_to_cbd.csv\n",
      "Processing chunk 161 (rows 4800–4829), size=30\n",
      "✅ Saved chunk 161 -> domain_to_cbd.csv\n",
      "Processing chunk 162 (rows 4830–4859), size=30\n",
      "✅ Saved chunk 162 -> domain_to_cbd.csv\n",
      "Processing chunk 163 (rows 4860–4889), size=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 1st time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n",
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 2nd time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved chunk 163 -> domain_to_cbd.csv\n",
      "Processing chunk 164 (rows 4890–4919), size=30\n",
      "✅ Saved chunk 164 -> domain_to_cbd.csv\n",
      "Processing chunk 165 (rows 4920–4949), size=30\n",
      "✅ Saved chunk 165 -> domain_to_cbd.csv\n",
      "Processing chunk 166 (rows 4950–4979), size=30\n",
      "✅ Saved chunk 166 -> domain_to_cbd.csv\n",
      "Processing chunk 167 (rows 4980–5009), size=30\n",
      "✅ Saved chunk 167 -> domain_to_cbd.csv\n",
      "Processing chunk 168 (rows 5010–5039), size=30\n",
      "✅ Saved chunk 168 -> domain_to_cbd.csv\n",
      "Processing chunk 169 (rows 5040–5069), size=30\n",
      "✅ Saved chunk 169 -> domain_to_cbd.csv\n",
      "Processing chunk 170 (rows 5070–5099), size=30\n",
      "✅ Saved chunk 170 -> domain_to_cbd.csv\n",
      "Processing chunk 171 (rows 5100–5129), size=30\n",
      "✅ Saved chunk 171 -> domain_to_cbd.csv\n",
      "Processing chunk 172 (rows 5130–5159), size=30\n",
      "✅ Saved chunk 172 -> domain_to_cbd.csv\n",
      "Processing chunk 173 (rows 5160–5189), size=30\n",
      "✅ Saved chunk 173 -> domain_to_cbd.csv\n",
      "Processing chunk 174 (rows 5190–5219), size=30\n",
      "✅ Saved chunk 174 -> domain_to_cbd.csv\n",
      "Processing chunk 175 (rows 5220–5249), size=30\n",
      "✅ Saved chunk 175 -> domain_to_cbd.csv\n",
      "Processing chunk 176 (rows 5250–5279), size=30\n",
      "✅ Saved chunk 176 -> domain_to_cbd.csv\n",
      "Processing chunk 177 (rows 5280–5309), size=30\n",
      "✅ Saved chunk 177 -> domain_to_cbd.csv\n",
      "Processing chunk 178 (rows 5310–5339), size=30\n",
      "✅ Saved chunk 178 -> domain_to_cbd.csv\n",
      "Processing chunk 179 (rows 5340–5369), size=30\n",
      "✅ Saved chunk 179 -> domain_to_cbd.csv\n",
      "Processing chunk 180 (rows 5370–5399), size=30\n",
      "✅ Saved chunk 180 -> domain_to_cbd.csv\n",
      "Processing chunk 181 (rows 5400–5429), size=30\n",
      "✅ Saved chunk 181 -> domain_to_cbd.csv\n",
      "Processing chunk 182 (rows 5430–5459), size=30\n",
      "✅ Saved chunk 182 -> domain_to_cbd.csv\n",
      "Processing chunk 183 (rows 5460–5489), size=30\n",
      "✅ Saved chunk 183 -> domain_to_cbd.csv\n",
      "Processing chunk 184 (rows 5490–5519), size=30\n",
      "✅ Saved chunk 184 -> domain_to_cbd.csv\n",
      "Processing chunk 185 (rows 5520–5549), size=30\n",
      "✅ Saved chunk 185 -> domain_to_cbd.csv\n",
      "Processing chunk 186 (rows 5550–5579), size=30\n",
      "✅ Saved chunk 186 -> domain_to_cbd.csv\n",
      "Processing chunk 187 (rows 5580–5609), size=30\n",
      "✅ Saved chunk 187 -> domain_to_cbd.csv\n",
      "Processing chunk 188 (rows 5610–5639), size=30\n",
      "✅ Saved chunk 188 -> domain_to_cbd.csv\n",
      "Processing chunk 189 (rows 5640–5669), size=30\n",
      "✅ Saved chunk 189 -> domain_to_cbd.csv\n",
      "Processing chunk 190 (rows 5670–5699), size=30\n",
      "✅ Saved chunk 190 -> domain_to_cbd.csv\n",
      "Processing chunk 191 (rows 5700–5729), size=30\n",
      "✅ Saved chunk 191 -> domain_to_cbd.csv\n",
      "Processing chunk 192 (rows 5730–5759), size=30\n",
      "✅ Saved chunk 192 -> domain_to_cbd.csv\n",
      "Processing chunk 193 (rows 5760–5789), size=30\n",
      "✅ Saved chunk 193 -> domain_to_cbd.csv\n",
      "Processing chunk 194 (rows 5790–5819), size=30\n",
      "✅ Saved chunk 194 -> domain_to_cbd.csv\n",
      "Processing chunk 195 (rows 5820–5849), size=30\n",
      "✅ Saved chunk 195 -> domain_to_cbd.csv\n",
      "Processing chunk 196 (rows 5850–5879), size=30\n",
      "✅ Saved chunk 196 -> domain_to_cbd.csv\n",
      "Processing chunk 197 (rows 5880–5909), size=30\n",
      "✅ Saved chunk 197 -> domain_to_cbd.csv\n",
      "Processing chunk 198 (rows 5910–5939), size=30\n",
      "✅ Saved chunk 198 -> domain_to_cbd.csv\n",
      "Processing chunk 199 (rows 5940–5969), size=30\n",
      "✅ Saved chunk 199 -> domain_to_cbd.csv\n",
      "Processing chunk 200 (rows 5970–5999), size=30\n",
      "✅ Saved chunk 200 -> domain_to_cbd.csv\n",
      "Processing chunk 201 (rows 6000–6029), size=30\n",
      "✅ Saved chunk 201 -> domain_to_cbd.csv\n",
      "Processing chunk 202 (rows 6030–6059), size=30\n",
      "✅ Saved chunk 202 -> domain_to_cbd.csv\n",
      "Processing chunk 203 (rows 6060–6089), size=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 1st time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved chunk 203 -> domain_to_cbd.csv\n",
      "Processing chunk 204 (rows 6090–6119), size=30\n",
      "✅ Saved chunk 204 -> domain_to_cbd.csv\n",
      "Processing chunk 205 (rows 6120–6149), size=30\n",
      "✅ Saved chunk 205 -> domain_to_cbd.csv\n",
      "Processing chunk 206 (rows 6150–6179), size=30\n",
      "✅ Saved chunk 206 -> domain_to_cbd.csv\n",
      "Processing chunk 207 (rows 6180–6209), size=30\n",
      "✅ Saved chunk 207 -> domain_to_cbd.csv\n",
      "Processing chunk 208 (rows 6210–6239), size=30\n",
      "✅ Saved chunk 208 -> domain_to_cbd.csv\n",
      "Processing chunk 209 (rows 6240–6269), size=30\n",
      "✅ Saved chunk 209 -> domain_to_cbd.csv\n",
      "Processing chunk 210 (rows 6270–6299), size=30\n",
      "✅ Saved chunk 210 -> domain_to_cbd.csv\n",
      "Processing chunk 211 (rows 6300–6329), size=30\n",
      "✅ Saved chunk 211 -> domain_to_cbd.csv\n",
      "Processing chunk 212 (rows 6330–6359), size=30\n",
      "✅ Saved chunk 212 -> domain_to_cbd.csv\n",
      "Processing chunk 213 (rows 6360–6389), size=30\n",
      "✅ Saved chunk 213 -> domain_to_cbd.csv\n",
      "Processing chunk 214 (rows 6390–6419), size=30\n",
      "✅ Saved chunk 214 -> domain_to_cbd.csv\n",
      "Processing chunk 215 (rows 6420–6449), size=30\n",
      "✅ Saved chunk 215 -> domain_to_cbd.csv\n",
      "Processing chunk 216 (rows 6450–6479), size=30\n",
      "✅ Saved chunk 216 -> domain_to_cbd.csv\n",
      "Processing chunk 217 (rows 6480–6509), size=30\n",
      "✅ Saved chunk 217 -> domain_to_cbd.csv\n",
      "Processing chunk 218 (rows 6510–6539), size=30\n",
      "✅ Saved chunk 218 -> domain_to_cbd.csv\n",
      "Processing chunk 219 (rows 6540–6569), size=30\n",
      "✅ Saved chunk 219 -> domain_to_cbd.csv\n",
      "Processing chunk 220 (rows 6570–6599), size=30\n",
      "✅ Saved chunk 220 -> domain_to_cbd.csv\n",
      "Processing chunk 221 (rows 6600–6629), size=30\n",
      "✅ Saved chunk 221 -> domain_to_cbd.csv\n",
      "Processing chunk 222 (rows 6630–6659), size=30\n",
      "✅ Saved chunk 222 -> domain_to_cbd.csv\n",
      "Processing chunk 223 (rows 6660–6689), size=30\n",
      "✅ Saved chunk 223 -> domain_to_cbd.csv\n",
      "Processing chunk 224 (rows 6690–6719), size=30\n",
      "✅ Saved chunk 224 -> domain_to_cbd.csv\n",
      "Processing chunk 225 (rows 6720–6749), size=30\n",
      "✅ Saved chunk 225 -> domain_to_cbd.csv\n",
      "Processing chunk 226 (rows 6750–6779), size=30\n",
      "✅ Saved chunk 226 -> domain_to_cbd.csv\n",
      "Processing chunk 227 (rows 6780–6809), size=30\n",
      "✅ Saved chunk 227 -> domain_to_cbd.csv\n",
      "Processing chunk 228 (rows 6810–6839), size=30\n",
      "✅ Saved chunk 228 -> domain_to_cbd.csv\n",
      "Processing chunk 229 (rows 6840–6869), size=30\n",
      "✅ Saved chunk 229 -> domain_to_cbd.csv\n",
      "Processing chunk 230 (rows 6870–6899), size=30\n",
      "✅ Saved chunk 230 -> domain_to_cbd.csv\n",
      "Processing chunk 231 (rows 6900–6929), size=30\n",
      "✅ Saved chunk 231 -> domain_to_cbd.csv\n",
      "Processing chunk 232 (rows 6930–6959), size=30\n",
      "✅ Saved chunk 232 -> domain_to_cbd.csv\n",
      "Processing chunk 233 (rows 6960–6989), size=30\n",
      "✅ Saved chunk 233 -> domain_to_cbd.csv\n",
      "Processing chunk 234 (rows 6990–7019), size=30\n",
      "✅ Saved chunk 234 -> domain_to_cbd.csv\n",
      "Processing chunk 235 (rows 7020–7049), size=30\n",
      "✅ Saved chunk 235 -> domain_to_cbd.csv\n",
      "Processing chunk 236 (rows 7050–7079), size=30\n",
      "✅ Saved chunk 236 -> domain_to_cbd.csv\n",
      "Processing chunk 237 (rows 7080–7109), size=30\n",
      "✅ Saved chunk 237 -> domain_to_cbd.csv\n",
      "Processing chunk 238 (rows 7110–7139), size=30\n",
      "✅ Saved chunk 238 -> domain_to_cbd.csv\n",
      "Processing chunk 239 (rows 7140–7169), size=30\n",
      "✅ Saved chunk 239 -> domain_to_cbd.csv\n",
      "Processing chunk 240 (rows 7170–7199), size=30\n",
      "✅ Saved chunk 240 -> domain_to_cbd.csv\n",
      "Processing chunk 241 (rows 7200–7229), size=30\n",
      "✅ Saved chunk 241 -> domain_to_cbd.csv\n",
      "Processing chunk 242 (rows 7230–7259), size=30\n",
      "✅ Saved chunk 242 -> domain_to_cbd.csv\n",
      "Processing chunk 243 (rows 7260–7289), size=30\n",
      "✅ Saved chunk 243 -> domain_to_cbd.csv\n",
      "Processing chunk 244 (rows 7290–7319), size=30\n",
      "✅ Saved chunk 244 -> domain_to_cbd.csv\n",
      "Processing chunk 245 (rows 7320–7349), size=30\n",
      "✅ Saved chunk 245 -> domain_to_cbd.csv\n",
      "Processing chunk 246 (rows 7350–7379), size=30\n",
      "✅ Saved chunk 246 -> domain_to_cbd.csv\n",
      "Processing chunk 247 (rows 7380–7409), size=30\n",
      "✅ Saved chunk 247 -> domain_to_cbd.csv\n",
      "Processing chunk 248 (rows 7410–7439), size=30\n",
      "✅ Saved chunk 248 -> domain_to_cbd.csv\n",
      "Processing chunk 249 (rows 7440–7469), size=30\n",
      "✅ Saved chunk 249 -> domain_to_cbd.csv\n",
      "Processing chunk 250 (rows 7470–7499), size=30\n",
      "✅ Saved chunk 250 -> domain_to_cbd.csv\n",
      "Processing chunk 251 (rows 7500–7529), size=30\n",
      "✅ Saved chunk 251 -> domain_to_cbd.csv\n",
      "Processing chunk 252 (rows 7530–7559), size=30\n",
      "✅ Saved chunk 252 -> domain_to_cbd.csv\n",
      "Processing chunk 253 (rows 7560–7589), size=30\n",
      "✅ Saved chunk 253 -> domain_to_cbd.csv\n",
      "Processing chunk 254 (rows 7590–7619), size=30\n",
      "✅ Saved chunk 254 -> domain_to_cbd.csv\n",
      "Processing chunk 255 (rows 7620–7649), size=30\n",
      "✅ Saved chunk 255 -> domain_to_cbd.csv\n",
      "Processing chunk 256 (rows 7650–7679), size=30\n",
      "✅ Saved chunk 256 -> domain_to_cbd.csv\n",
      "Processing chunk 257 (rows 7680–7709), size=30\n",
      "✅ Saved chunk 257 -> domain_to_cbd.csv\n",
      "Processing chunk 258 (rows 7710–7739), size=30\n",
      "✅ Saved chunk 258 -> domain_to_cbd.csv\n",
      "Processing chunk 259 (rows 7740–7769), size=30\n",
      "✅ Saved chunk 259 -> domain_to_cbd.csv\n",
      "Processing chunk 260 (rows 7770–7799), size=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 1st time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved chunk 260 -> domain_to_cbd.csv\n",
      "Processing chunk 261 (rows 7800–7829), size=30\n",
      "✅ Saved chunk 261 -> domain_to_cbd.csv\n",
      "Processing chunk 262 (rows 7830–7859), size=30\n",
      "✅ Saved chunk 262 -> domain_to_cbd.csv\n",
      "Processing chunk 263 (rows 7860–7889), size=30\n",
      "✅ Saved chunk 263 -> domain_to_cbd.csv\n",
      "Processing chunk 264 (rows 7890–7919), size=30\n",
      "✅ Saved chunk 264 -> domain_to_cbd.csv\n",
      "Processing chunk 265 (rows 7920–7949), size=30\n",
      "✅ Saved chunk 265 -> domain_to_cbd.csv\n",
      "Processing chunk 266 (rows 7950–7979), size=30\n",
      "✅ Saved chunk 266 -> domain_to_cbd.csv\n",
      "Processing chunk 267 (rows 7980–8009), size=30\n",
      "✅ Saved chunk 267 -> domain_to_cbd.csv\n",
      "Processing chunk 268 (rows 8010–8039), size=30\n",
      "✅ Saved chunk 268 -> domain_to_cbd.csv\n",
      "Processing chunk 269 (rows 8040–8069), size=30\n",
      "✅ Saved chunk 269 -> domain_to_cbd.csv\n",
      "Processing chunk 270 (rows 8070–8099), size=30\n",
      "✅ Saved chunk 270 -> domain_to_cbd.csv\n",
      "Processing chunk 271 (rows 8100–8129), size=30\n",
      "✅ Saved chunk 271 -> domain_to_cbd.csv\n",
      "Processing chunk 272 (rows 8130–8159), size=30\n",
      "✅ Saved chunk 272 -> domain_to_cbd.csv\n",
      "Processing chunk 273 (rows 8160–8189), size=30\n",
      "✅ Saved chunk 273 -> domain_to_cbd.csv\n",
      "Processing chunk 274 (rows 8190–8219), size=30\n",
      "✅ Saved chunk 274 -> domain_to_cbd.csv\n",
      "Processing chunk 275 (rows 8220–8249), size=30\n",
      "✅ Saved chunk 275 -> domain_to_cbd.csv\n",
      "Processing chunk 276 (rows 8250–8279), size=30\n",
      "✅ Saved chunk 276 -> domain_to_cbd.csv\n",
      "Processing chunk 277 (rows 8280–8309), size=30\n",
      "✅ Saved chunk 277 -> domain_to_cbd.csv\n",
      "Processing chunk 278 (rows 8310–8339), size=30\n",
      "✅ Saved chunk 278 -> domain_to_cbd.csv\n",
      "Processing chunk 279 (rows 8340–8369), size=30\n",
      "✅ Saved chunk 279 -> domain_to_cbd.csv\n",
      "Processing chunk 280 (rows 8370–8399), size=30\n",
      "✅ Saved chunk 280 -> domain_to_cbd.csv\n",
      "Processing chunk 281 (rows 8400–8429), size=30\n",
      "✅ Saved chunk 281 -> domain_to_cbd.csv\n",
      "Processing chunk 282 (rows 8430–8459), size=30\n",
      "✅ Saved chunk 282 -> domain_to_cbd.csv\n",
      "Processing chunk 283 (rows 8460–8489), size=30\n",
      "✅ Saved chunk 283 -> domain_to_cbd.csv\n",
      "Processing chunk 284 (rows 8490–8519), size=30\n",
      "✅ Saved chunk 284 -> domain_to_cbd.csv\n",
      "Processing chunk 285 (rows 8520–8549), size=30\n",
      "✅ Saved chunk 285 -> domain_to_cbd.csv\n",
      "Processing chunk 286 (rows 8550–8579), size=30\n",
      "✅ Saved chunk 286 -> domain_to_cbd.csv\n",
      "Processing chunk 287 (rows 8580–8609), size=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 1st time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved chunk 287 -> domain_to_cbd.csv\n",
      "Processing chunk 288 (rows 8610–8639), size=30\n",
      "✅ Saved chunk 288 -> domain_to_cbd.csv\n",
      "Processing chunk 289 (rows 8640–8669), size=30\n",
      "✅ Saved chunk 289 -> domain_to_cbd.csv\n",
      "Processing chunk 290 (rows 8670–8699), size=30\n",
      "✅ Saved chunk 290 -> domain_to_cbd.csv\n",
      "Processing chunk 291 (rows 8700–8729), size=30\n",
      "✅ Saved chunk 291 -> domain_to_cbd.csv\n",
      "Processing chunk 292 (rows 8730–8759), size=30\n",
      "✅ Saved chunk 292 -> domain_to_cbd.csv\n",
      "Processing chunk 293 (rows 8760–8789), size=30\n",
      "✅ Saved chunk 293 -> domain_to_cbd.csv\n",
      "Processing chunk 294 (rows 8790–8819), size=30\n",
      "✅ Saved chunk 294 -> domain_to_cbd.csv\n",
      "Processing chunk 295 (rows 8820–8849), size=30\n",
      "✅ Saved chunk 295 -> domain_to_cbd.csv\n",
      "Processing chunk 296 (rows 8850–8879), size=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 1st time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n",
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 2nd time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved chunk 296 -> domain_to_cbd.csv\n",
      "Processing chunk 297 (rows 8880–8909), size=30\n",
      "✅ Saved chunk 297 -> domain_to_cbd.csv\n",
      "Processing chunk 298 (rows 8910–8939), size=30\n",
      "✅ Saved chunk 298 -> domain_to_cbd.csv\n",
      "Processing chunk 299 (rows 8940–8969), size=30\n",
      "✅ Saved chunk 299 -> domain_to_cbd.csv\n",
      "Processing chunk 300 (rows 8970–8999), size=30\n",
      "✅ Saved chunk 300 -> domain_to_cbd.csv\n",
      "Processing chunk 301 (rows 9000–9029), size=30\n",
      "✅ Saved chunk 301 -> domain_to_cbd.csv\n",
      "Processing chunk 302 (rows 9030–9059), size=30\n",
      "✅ Saved chunk 302 -> domain_to_cbd.csv\n",
      "Processing chunk 303 (rows 9060–9089), size=30\n",
      "✅ Saved chunk 303 -> domain_to_cbd.csv\n",
      "Processing chunk 304 (rows 9090–9119), size=30\n",
      "✅ Saved chunk 304 -> domain_to_cbd.csv\n",
      "Processing chunk 305 (rows 9120–9149), size=30\n",
      "✅ Saved chunk 305 -> domain_to_cbd.csv\n",
      "Processing chunk 306 (rows 9150–9179), size=30\n",
      "✅ Saved chunk 306 -> domain_to_cbd.csv\n",
      "Processing chunk 307 (rows 9180–9209), size=30\n",
      "✅ Saved chunk 307 -> domain_to_cbd.csv\n",
      "Processing chunk 308 (rows 9210–9239), size=30\n",
      "✅ Saved chunk 308 -> domain_to_cbd.csv\n",
      "Processing chunk 309 (rows 9240–9269), size=30\n",
      "✅ Saved chunk 309 -> domain_to_cbd.csv\n",
      "Processing chunk 310 (rows 9270–9299), size=30\n",
      "✅ Saved chunk 310 -> domain_to_cbd.csv\n",
      "Processing chunk 311 (rows 9300–9329), size=30\n",
      "✅ Saved chunk 311 -> domain_to_cbd.csv\n",
      "Processing chunk 312 (rows 9330–9359), size=30\n",
      "✅ Saved chunk 312 -> domain_to_cbd.csv\n",
      "Processing chunk 313 (rows 9360–9389), size=30\n",
      "✅ Saved chunk 313 -> domain_to_cbd.csv\n",
      "Processing chunk 314 (rows 9390–9419), size=30\n",
      "✅ Saved chunk 314 -> domain_to_cbd.csv\n",
      "Processing chunk 315 (rows 9420–9449), size=30\n",
      "✅ Saved chunk 315 -> domain_to_cbd.csv\n",
      "Processing chunk 316 (rows 9450–9479), size=30\n",
      "✅ Saved chunk 316 -> domain_to_cbd.csv\n",
      "Processing chunk 317 (rows 9480–9509), size=30\n",
      "✅ Saved chunk 317 -> domain_to_cbd.csv\n",
      "Processing chunk 318 (rows 9510–9539), size=30\n",
      "✅ Saved chunk 318 -> domain_to_cbd.csv\n",
      "Processing chunk 319 (rows 9540–9569), size=30\n",
      "✅ Saved chunk 319 -> domain_to_cbd.csv\n",
      "Processing chunk 320 (rows 9570–9599), size=30\n",
      "✅ Saved chunk 320 -> domain_to_cbd.csv\n",
      "Processing chunk 321 (rows 9600–9629), size=30\n",
      "✅ Saved chunk 321 -> domain_to_cbd.csv\n",
      "Processing chunk 322 (rows 9630–9659), size=30\n",
      "✅ Saved chunk 322 -> domain_to_cbd.csv\n",
      "Processing chunk 323 (rows 9660–9689), size=30\n",
      "✅ Saved chunk 323 -> domain_to_cbd.csv\n",
      "Processing chunk 324 (rows 9690–9719), size=30\n",
      "✅ Saved chunk 324 -> domain_to_cbd.csv\n",
      "Processing chunk 325 (rows 9720–9749), size=30\n",
      "✅ Saved chunk 325 -> domain_to_cbd.csv\n",
      "Processing chunk 326 (rows 9750–9779), size=30\n",
      "✅ Saved chunk 326 -> domain_to_cbd.csv\n",
      "Processing chunk 327 (rows 9780–9809), size=30\n",
      "✅ Saved chunk 327 -> domain_to_cbd.csv\n",
      "Processing chunk 328 (rows 9810–9839), size=30\n",
      "✅ Saved chunk 328 -> domain_to_cbd.csv\n",
      "Processing chunk 329 (rows 9840–9869), size=30\n",
      "✅ Saved chunk 329 -> domain_to_cbd.csv\n",
      "Processing chunk 330 (rows 9870–9899), size=30\n",
      "✅ Saved chunk 330 -> domain_to_cbd.csv\n",
      "Processing chunk 331 (rows 9900–9929), size=30\n",
      "✅ Saved chunk 331 -> domain_to_cbd.csv\n",
      "Processing chunk 332 (rows 9930–9959), size=30\n",
      "✅ Saved chunk 332 -> domain_to_cbd.csv\n",
      "Processing chunk 333 (rows 9960–9989), size=30\n",
      "✅ Saved chunk 333 -> domain_to_cbd.csv\n",
      "Processing chunk 334 (rows 9990–10019), size=30\n",
      "✅ Saved chunk 334 -> domain_to_cbd.csv\n",
      "Processing chunk 335 (rows 10020–10049), size=30\n",
      "✅ Saved chunk 335 -> domain_to_cbd.csv\n",
      "Processing chunk 336 (rows 10050–10079), size=30\n",
      "✅ Saved chunk 336 -> domain_to_cbd.csv\n",
      "Processing chunk 337 (rows 10080–10109), size=30\n",
      "✅ Saved chunk 337 -> domain_to_cbd.csv\n",
      "Processing chunk 338 (rows 10110–10139), size=30\n",
      "✅ Saved chunk 338 -> domain_to_cbd.csv\n",
      "Processing chunk 339 (rows 10140–10169), size=30\n",
      "✅ Saved chunk 339 -> domain_to_cbd.csv\n",
      "Processing chunk 340 (rows 10170–10199), size=30\n",
      "✅ Saved chunk 340 -> domain_to_cbd.csv\n",
      "Processing chunk 341 (rows 10200–10229), size=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 1st time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n",
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 2nd time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved chunk 341 -> domain_to_cbd.csv\n",
      "Processing chunk 342 (rows 10230–10259), size=30\n",
      "✅ Saved chunk 342 -> domain_to_cbd.csv\n",
      "Processing chunk 343 (rows 10260–10289), size=30\n",
      "✅ Saved chunk 343 -> domain_to_cbd.csv\n",
      "Processing chunk 344 (rows 10290–10319), size=30\n",
      "✅ Saved chunk 344 -> domain_to_cbd.csv\n",
      "Processing chunk 345 (rows 10320–10349), size=30\n",
      "✅ Saved chunk 345 -> domain_to_cbd.csv\n",
      "Processing chunk 346 (rows 10350–10379), size=30\n",
      "✅ Saved chunk 346 -> domain_to_cbd.csv\n",
      "Processing chunk 347 (rows 10380–10409), size=30\n",
      "✅ Saved chunk 347 -> domain_to_cbd.csv\n",
      "Processing chunk 348 (rows 10410–10439), size=30\n",
      "✅ Saved chunk 348 -> domain_to_cbd.csv\n",
      "Processing chunk 349 (rows 10440–10469), size=30\n",
      "✅ Saved chunk 349 -> domain_to_cbd.csv\n",
      "Processing chunk 350 (rows 10470–10499), size=30\n",
      "✅ Saved chunk 350 -> domain_to_cbd.csv\n",
      "Processing chunk 351 (rows 10500–10529), size=30\n",
      "✅ Saved chunk 351 -> domain_to_cbd.csv\n",
      "Processing chunk 352 (rows 10530–10559), size=30\n",
      "✅ Saved chunk 352 -> domain_to_cbd.csv\n",
      "Processing chunk 353 (rows 10560–10589), size=30\n",
      "✅ Saved chunk 353 -> domain_to_cbd.csv\n",
      "Processing chunk 354 (rows 10590–10619), size=30\n",
      "✅ Saved chunk 354 -> domain_to_cbd.csv\n",
      "Processing chunk 355 (rows 10620–10649), size=30\n",
      "✅ Saved chunk 355 -> domain_to_cbd.csv\n",
      "Processing chunk 356 (rows 10650–10679), size=30\n",
      "✅ Saved chunk 356 -> domain_to_cbd.csv\n",
      "Processing chunk 357 (rows 10680–10709), size=30\n",
      "✅ Saved chunk 357 -> domain_to_cbd.csv\n",
      "Processing chunk 358 (rows 10710–10739), size=30\n",
      "✅ Saved chunk 358 -> domain_to_cbd.csv\n",
      "Processing chunk 359 (rows 10740–10769), size=30\n",
      "✅ Saved chunk 359 -> domain_to_cbd.csv\n",
      "Processing chunk 360 (rows 10770–10799), size=30\n",
      "✅ Saved chunk 360 -> domain_to_cbd.csv\n",
      "Processing chunk 361 (rows 10800–10829), size=30\n",
      "✅ Saved chunk 361 -> domain_to_cbd.csv\n",
      "Processing chunk 362 (rows 10830–10859), size=30\n",
      "✅ Saved chunk 362 -> domain_to_cbd.csv\n",
      "Processing chunk 363 (rows 10860–10889), size=30\n",
      "✅ Saved chunk 363 -> domain_to_cbd.csv\n",
      "Processing chunk 364 (rows 10890–10919), size=30\n",
      "✅ Saved chunk 364 -> domain_to_cbd.csv\n",
      "Processing chunk 365 (rows 10920–10949), size=30\n",
      "✅ Saved chunk 365 -> domain_to_cbd.csv\n",
      "Processing chunk 366 (rows 10950–10979), size=30\n",
      "✅ Saved chunk 366 -> domain_to_cbd.csv\n",
      "Processing chunk 367 (rows 10980–11009), size=30\n",
      "✅ Saved chunk 367 -> domain_to_cbd.csv\n",
      "Processing chunk 368 (rows 11010–11039), size=30\n",
      "✅ Saved chunk 368 -> domain_to_cbd.csv\n",
      "Processing chunk 369 (rows 11040–11069), size=30\n",
      "✅ Saved chunk 369 -> domain_to_cbd.csv\n",
      "Processing chunk 370 (rows 11070–11099), size=30\n",
      "✅ Saved chunk 370 -> domain_to_cbd.csv\n",
      "Processing chunk 371 (rows 11100–11129), size=30\n",
      "✅ Saved chunk 371 -> domain_to_cbd.csv\n",
      "Processing chunk 372 (rows 11130–11159), size=30\n",
      "✅ Saved chunk 372 -> domain_to_cbd.csv\n",
      "Processing chunk 373 (rows 11160–11189), size=30\n",
      "✅ Saved chunk 373 -> domain_to_cbd.csv\n",
      "Processing chunk 374 (rows 11190–11219), size=30\n",
      "✅ Saved chunk 374 -> domain_to_cbd.csv\n",
      "Processing chunk 375 (rows 11220–11249), size=30\n",
      "✅ Saved chunk 375 -> domain_to_cbd.csv\n",
      "Processing chunk 376 (rows 11250–11279), size=30\n",
      "✅ Saved chunk 376 -> domain_to_cbd.csv\n",
      "Processing chunk 377 (rows 11280–11309), size=30\n",
      "✅ Saved chunk 377 -> domain_to_cbd.csv\n",
      "Processing chunk 378 (rows 11310–11339), size=30\n",
      "✅ Saved chunk 378 -> domain_to_cbd.csv\n",
      "Processing chunk 379 (rows 11340–11369), size=30\n",
      "✅ Saved chunk 379 -> domain_to_cbd.csv\n",
      "Processing chunk 380 (rows 11370–11399), size=30\n",
      "✅ Saved chunk 380 -> domain_to_cbd.csv\n",
      "Processing chunk 381 (rows 11400–11429), size=30\n",
      "✅ Saved chunk 381 -> domain_to_cbd.csv\n",
      "Processing chunk 382 (rows 11430–11459), size=30\n",
      "✅ Saved chunk 382 -> domain_to_cbd.csv\n",
      "Processing chunk 383 (rows 11460–11489), size=30\n",
      "✅ Saved chunk 383 -> domain_to_cbd.csv\n",
      "Processing chunk 384 (rows 11490–11519), size=30\n",
      "✅ Saved chunk 384 -> domain_to_cbd.csv\n",
      "Processing chunk 385 (rows 11520–11549), size=30\n",
      "✅ Saved chunk 385 -> domain_to_cbd.csv\n",
      "Processing chunk 386 (rows 11550–11579), size=30\n",
      "✅ Saved chunk 386 -> domain_to_cbd.csv\n",
      "Processing chunk 387 (rows 11580–11609), size=30\n",
      "✅ Saved chunk 387 -> domain_to_cbd.csv\n",
      "Processing chunk 388 (rows 11610–11639), size=30\n",
      "✅ Saved chunk 388 -> domain_to_cbd.csv\n",
      "Processing chunk 389 (rows 11640–11669), size=30\n",
      "✅ Saved chunk 389 -> domain_to_cbd.csv\n",
      "Processing chunk 390 (rows 11670–11699), size=30\n",
      "✅ Saved chunk 390 -> domain_to_cbd.csv\n",
      "Processing chunk 391 (rows 11700–11729), size=30\n",
      "✅ Saved chunk 391 -> domain_to_cbd.csv\n",
      "Processing chunk 392 (rows 11730–11759), size=30\n",
      "✅ Saved chunk 392 -> domain_to_cbd.csv\n",
      "Processing chunk 393 (rows 11760–11789), size=30\n",
      "✅ Saved chunk 393 -> domain_to_cbd.csv\n",
      "Processing chunk 394 (rows 11790–11819), size=30\n",
      "✅ Saved chunk 394 -> domain_to_cbd.csv\n",
      "Processing chunk 395 (rows 11820–11849), size=30\n",
      "✅ Saved chunk 395 -> domain_to_cbd.csv\n",
      "Processing chunk 396 (rows 11850–11879), size=30\n",
      "✅ Saved chunk 396 -> domain_to_cbd.csv\n",
      "Processing chunk 397 (rows 11880–11909), size=30\n",
      "✅ Saved chunk 397 -> domain_to_cbd.csv\n",
      "Processing chunk 398 (rows 11910–11939), size=30\n",
      "✅ Saved chunk 398 -> domain_to_cbd.csv\n",
      "Processing chunk 399 (rows 11940–11969), size=30\n",
      "✅ Saved chunk 399 -> domain_to_cbd.csv\n",
      "Processing chunk 400 (rows 11970–11999), size=30\n",
      "✅ Saved chunk 400 -> domain_to_cbd.csv\n",
      "Processing chunk 401 (rows 12000–12029), size=30\n",
      "✅ Saved chunk 401 -> domain_to_cbd.csv\n",
      "Processing chunk 402 (rows 12030–12059), size=30\n",
      "✅ Saved chunk 402 -> domain_to_cbd.csv\n",
      "Processing chunk 403 (rows 12060–12089), size=30\n",
      "✅ Saved chunk 403 -> domain_to_cbd.csv\n",
      "Processing chunk 404 (rows 12090–12119), size=30\n",
      "✅ Saved chunk 404 -> domain_to_cbd.csv\n",
      "Processing chunk 405 (rows 12120–12149), size=30\n",
      "✅ Saved chunk 405 -> domain_to_cbd.csv\n",
      "Processing chunk 406 (rows 12150–12179), size=30\n",
      "✅ Saved chunk 406 -> domain_to_cbd.csv\n",
      "Processing chunk 407 (rows 12180–12209), size=30\n",
      "✅ Saved chunk 407 -> domain_to_cbd.csv\n",
      "Processing chunk 408 (rows 12210–12239), size=30\n",
      "✅ Saved chunk 408 -> domain_to_cbd.csv\n",
      "Processing chunk 409 (rows 12240–12269), size=30\n",
      "✅ Saved chunk 409 -> domain_to_cbd.csv\n",
      "Processing chunk 410 (rows 12270–12299), size=30\n",
      "✅ Saved chunk 410 -> domain_to_cbd.csv\n",
      "Processing chunk 411 (rows 12300–12329), size=30\n",
      "✅ Saved chunk 411 -> domain_to_cbd.csv\n",
      "Processing chunk 412 (rows 12330–12359), size=30\n",
      "✅ Saved chunk 412 -> domain_to_cbd.csv\n",
      "Processing chunk 413 (rows 12360–12389), size=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 1st time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved chunk 413 -> domain_to_cbd.csv\n",
      "Processing chunk 414 (rows 12390–12419), size=30\n",
      "✅ Saved chunk 414 -> domain_to_cbd.csv\n",
      "Processing chunk 415 (rows 12420–12449), size=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 1st time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n",
      "/home/eeamanda/.local/lib/python3.10/site-packages/openrouteservice/client.py:211: UserWarning: Rate limit exceeded. Retrying for the 2nd time.\n",
      "  warnings.warn('Rate limit exceeded. Retrying for the {0}{1} time.'.format(retry_counter + 1,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved chunk 415 -> domain_to_cbd.csv\n",
      "Processing chunk 416 (rows 12450–12479), size=30\n",
      "✅ Saved chunk 416 -> domain_to_cbd.csv\n",
      "Processing chunk 417 (rows 12480–12509), size=30\n",
      "✅ Saved chunk 417 -> domain_to_cbd.csv\n",
      "Processing chunk 418 (rows 12510–12539), size=30\n",
      "✅ Saved chunk 418 -> domain_to_cbd.csv\n",
      "Processing chunk 419 (rows 12540–12569), size=30\n",
      "✅ Saved chunk 419 -> domain_to_cbd.csv\n",
      "Processing chunk 420 (rows 12570–12599), size=30\n",
      "✅ Saved chunk 420 -> domain_to_cbd.csv\n",
      "Processing chunk 421 (rows 12600–12617), size=18\n",
      "✅ Saved chunk 421 -> domain_to_cbd.csv\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "\n",
    "compute_domain_to_cbd(\n",
    "    domain_gdf=domain_gdf,\n",
    "    output_csv=\"domain_to_cbd.csv\",\n",
    "    chunk_size=30,\n",
    "    start_row=0\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
