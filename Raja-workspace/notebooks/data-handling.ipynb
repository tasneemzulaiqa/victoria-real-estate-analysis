{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f813822",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66a787a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found sheets: ['1 bedroom flat', '2 bedroom flat', '3 bedroom flat', '2 bedroom house', '3 bedroom house', '4 bedroom house', 'All properties']\n",
      "[split] Saved: /Users/rajaa/Desktop/Applied Data Science MAST30034/project-2-group-real-estate-industry-project-7-2025/Raja-workspace/notebooks/data/raw/split_sheets/1_bedroom_flat.csv\n",
      "[split] Saved: /Users/rajaa/Desktop/Applied Data Science MAST30034/project-2-group-real-estate-industry-project-7-2025/Raja-workspace/notebooks/data/raw/split_sheets/2_bedroom_flat.csv\n",
      "[split] Saved: /Users/rajaa/Desktop/Applied Data Science MAST30034/project-2-group-real-estate-industry-project-7-2025/Raja-workspace/notebooks/data/raw/split_sheets/3_bedroom_flat.csv\n",
      "[split] Saved: /Users/rajaa/Desktop/Applied Data Science MAST30034/project-2-group-real-estate-industry-project-7-2025/Raja-workspace/notebooks/data/raw/split_sheets/2_bedroom_house.csv\n",
      "[split] Saved: /Users/rajaa/Desktop/Applied Data Science MAST30034/project-2-group-real-estate-industry-project-7-2025/Raja-workspace/notebooks/data/raw/split_sheets/3_bedroom_house.csv\n",
      "[split] Saved: /Users/rajaa/Desktop/Applied Data Science MAST30034/project-2-group-real-estate-industry-project-7-2025/Raja-workspace/notebooks/data/raw/split_sheets/4_bedroom_house.csv\n",
      "[split] Saved: /Users/rajaa/Desktop/Applied Data Science MAST30034/project-2-group-real-estate-industry-project-7-2025/Raja-workspace/notebooks/data/raw/split_sheets/all_properties.csv\n",
      "[strip] Saved: /Users/rajaa/Desktop/Applied Data Science MAST30034/project-2-group-real-estate-industry-project-7-2025/Raja-workspace/notebooks/data/raw/split_sheets_stripped/1_bedroom_flat.csv\n",
      "[strip] Saved: /Users/rajaa/Desktop/Applied Data Science MAST30034/project-2-group-real-estate-industry-project-7-2025/Raja-workspace/notebooks/data/raw/split_sheets_stripped/2_bedroom_flat.csv\n",
      "[strip] Saved: /Users/rajaa/Desktop/Applied Data Science MAST30034/project-2-group-real-estate-industry-project-7-2025/Raja-workspace/notebooks/data/raw/split_sheets_stripped/2_bedroom_house.csv\n",
      "[strip] Saved: /Users/rajaa/Desktop/Applied Data Science MAST30034/project-2-group-real-estate-industry-project-7-2025/Raja-workspace/notebooks/data/raw/split_sheets_stripped/3_bedroom_flat.csv\n",
      "[strip] Saved: /Users/rajaa/Desktop/Applied Data Science MAST30034/project-2-group-real-estate-industry-project-7-2025/Raja-workspace/notebooks/data/raw/split_sheets_stripped/3_bedroom_house.csv\n",
      "[strip] Saved: /Users/rajaa/Desktop/Applied Data Science MAST30034/project-2-group-real-estate-industry-project-7-2025/Raja-workspace/notebooks/data/raw/split_sheets_stripped/4_bedroom_house.csv\n",
      "[strip] Saved: /Users/rajaa/Desktop/Applied Data Science MAST30034/project-2-group-real-estate-industry-project-7-2025/Raja-workspace/notebooks/data/raw/split_sheets_stripped/all_properties.csv\n",
      "[combine] Saved: /Users/rajaa/Desktop/Applied Data Science MAST30034/project-2-group-real-estate-industry-project-7-2025/Raja-workspace/notebooks/data/raw/combined_stripped.csv\n"
     ]
    }
   ],
   "source": [
    "# === Split sheets → CSV, then strip/clean (drop first row & col, set header, rename first col to 'Suburb') ===\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# -------- CONFIG: update only this path if needed --------\n",
    "EXCEL_PATH = Path(\"/Users/rajaa/Desktop/Applied Data Science MAST30034/project-2-group-real-estate-industry-project-7-2025/Raja-workspace/notebooks/data/Moving annual median rent by suburb and town - March quarter 2025.xlsx\")\n",
    "\n",
    "# Output folders (we'll keep things under a 'raw' dir next to the Excel file)\n",
    "RAW_DIR       = EXCEL_PATH.parent / \"raw\"\n",
    "SPLIT_DIR     = RAW_DIR / \"split_sheets\"\n",
    "STRIPPED_DIR  = RAW_DIR / \"split_sheets_stripped\"\n",
    "for d in (RAW_DIR, SPLIT_DIR, STRIPPED_DIR):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -------- STEP 1: split each sheet to CSV --------\n",
    "def _safe_name(s: str) -> str:\n",
    "    return re.sub(r\"[^A-Za-z0-9]+\", \"_\", s).strip(\"_\").lower()\n",
    "\n",
    "try:\n",
    "    xls = pd.ExcelFile(EXCEL_PATH)  # requires openpyxl for .xlsx\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\n",
    "        f\"Could not open Excel file. If missing, try: pip install openpyxl\\nOriginal error: {e}\"\n",
    "    )\n",
    "\n",
    "print(f\"Found sheets: {xls.sheet_names}\")\n",
    "\n",
    "for sheet_name in xls.sheet_names:\n",
    "    df = pd.read_excel(EXCEL_PATH, sheet_name=sheet_name)\n",
    "    out_csv = SPLIT_DIR / f\"{_safe_name(sheet_name)}.csv\"\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"[split] Saved: {out_csv}\")\n",
    "\n",
    "# -------- STEP 2: strip/clean each CSV --------\n",
    "produced = []\n",
    "for p in sorted(SPLIT_DIR.glob(\"*.csv\")):\n",
    "    # Read raw so file's first row really is index 0 (we'll promote a row to header later)\n",
    "    df = pd.read_csv(p, header=None, dtype=str)\n",
    "\n",
    "    # Guard: need at least 2 rows & 2 columns to drop first row/col\n",
    "    if df.shape[0] < 2 or df.shape[1] < 2:\n",
    "        print(f\"[skip] Too small to strip (needs ≥2 rows & ≥2 cols): {p.name}\")\n",
    "        continue\n",
    "\n",
    "    # Drop first row and first column\n",
    "    df2 = df.iloc[1:, 1:].reset_index(drop=True)\n",
    "\n",
    "    # Promote next row to header (the first row of df2 becomes the header)\n",
    "    new_header = df2.iloc[0].astype(str).str.strip()\n",
    "    df2 = df2.iloc[1:].reset_index(drop=True)\n",
    "    df2.columns = new_header\n",
    "\n",
    "    # Ensure the first column's header is exactly 'Suburb'\n",
    "    # (works even if header is empty/duplicated)\n",
    "    df2.columns = [\"Suburb\"] + df2.columns[1:].tolist()\n",
    "\n",
    "    # Save stripped/cleaned CSV (with header)\n",
    "    out = STRIPPED_DIR / p.name\n",
    "    df2.to_csv(out, index=False)\n",
    "    produced.append(out)\n",
    "    print(f\"[strip] Saved: {out}\")\n",
    "\n",
    "# -------- STEP 3 (optional): build a combined CSV from stripped files --------\n",
    "if produced:\n",
    "    combined = []\n",
    "    for p in produced:\n",
    "        tmp = pd.read_csv(p, dtype=str)\n",
    "        # add dwelling-type from filename for traceability, e.g. '1_bedroom_flat'\n",
    "        tmp[\"dwelling_file\"] = Path(p).stem\n",
    "        combined.append(tmp)\n",
    "    combined_df = pd.concat(combined, ignore_index=True)\n",
    "    combined_out = RAW_DIR / \"combined_stripped.csv\"\n",
    "    combined_df.to_csv(combined_out, index=False)\n",
    "    print(f\"[combine] Saved: {combined_out}\")\n",
    "else:\n",
    "    print(\"[combine] No stripped files produced; combined CSV not created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bb894ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/67/y3hlgrln6w72sw4d6d3mwhm80000gn/T/ipykernel_53408/1144541419.py:30: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  raw = raw.applymap(lambda x: None if pd.isna(x) else str(x).strip())\n",
      "/var/folders/67/y3hlgrln6w72sw4d6d3mwhm80000gn/T/ipykernel_53408/1144541419.py:62: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(_clean_cell)\n",
      "/var/folders/67/y3hlgrln6w72sw4d6d3mwhm80000gn/T/ipykernel_53408/1144541419.py:30: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  raw = raw.applymap(lambda x: None if pd.isna(x) else str(x).strip())\n",
      "/var/folders/67/y3hlgrln6w72sw4d6d3mwhm80000gn/T/ipykernel_53408/1144541419.py:62: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(_clean_cell)\n",
      "/var/folders/67/y3hlgrln6w72sw4d6d3mwhm80000gn/T/ipykernel_53408/1144541419.py:30: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  raw = raw.applymap(lambda x: None if pd.isna(x) else str(x).strip())\n",
      "/var/folders/67/y3hlgrln6w72sw4d6d3mwhm80000gn/T/ipykernel_53408/1144541419.py:62: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(_clean_cell)\n",
      "/var/folders/67/y3hlgrln6w72sw4d6d3mwhm80000gn/T/ipykernel_53408/1144541419.py:30: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  raw = raw.applymap(lambda x: None if pd.isna(x) else str(x).strip())\n",
      "/var/folders/67/y3hlgrln6w72sw4d6d3mwhm80000gn/T/ipykernel_53408/1144541419.py:62: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(_clean_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] 1_bedroom_flat.csv         -> 13639 rows\n",
      "[ok] 2_bedroom_flat.csv         -> 14708 rows\n",
      "[ok] 2_bedroom_house.csv        -> 14225 rows\n",
      "[ok] 3_bedroom_flat.csv         -> 14079 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/67/y3hlgrln6w72sw4d6d3mwhm80000gn/T/ipykernel_53408/1144541419.py:30: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  raw = raw.applymap(lambda x: None if pd.isna(x) else str(x).strip())\n",
      "/var/folders/67/y3hlgrln6w72sw4d6d3mwhm80000gn/T/ipykernel_53408/1144541419.py:62: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(_clean_cell)\n",
      "/var/folders/67/y3hlgrln6w72sw4d6d3mwhm80000gn/T/ipykernel_53408/1144541419.py:30: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  raw = raw.applymap(lambda x: None if pd.isna(x) else str(x).strip())\n",
      "/var/folders/67/y3hlgrln6w72sw4d6d3mwhm80000gn/T/ipykernel_53408/1144541419.py:62: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(_clean_cell)\n",
      "/var/folders/67/y3hlgrln6w72sw4d6d3mwhm80000gn/T/ipykernel_53408/1144541419.py:30: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  raw = raw.applymap(lambda x: None if pd.isna(x) else str(x).strip())\n",
      "/var/folders/67/y3hlgrln6w72sw4d6d3mwhm80000gn/T/ipykernel_53408/1144541419.py:62: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(_clean_cell)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] 3_bedroom_house.csv        -> 14529 rows\n",
      "[ok] 4_bedroom_house.csv        -> 14155 rows\n",
      "[ok] all_properties.csv         -> 14840 rows\n",
      "\n",
      "[done] Combined -> /Users/rajaa/Desktop/Applied Data Science MAST30034/project-2-group-real-estate-industry-project-7-2025/Raja-workspace/notebooks/data/raw/tidy_monthly/all_properties_tidy.csv  rows=100,175\n"
     ]
    }
   ],
   "source": [
    "# ==== Reshape property tables to tidy monthly format ==========================================\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ---- paths (edit IN_DIR only if yours is different) ----\n",
    "IN_DIR  = Path(\"/Users/rajaa/Desktop/Applied Data Science MAST30034/project-2-group-real-estate-industry-project-7-2025/Raja-workspace/notebooks/data/raw/split_sheets_stripped\")\n",
    "OUT_DIR = IN_DIR.parent / \"tidy_monthly\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- helpers ---------------------------------------------------------------------------------\n",
    "MONTH_ABBR = [\"Jan\",\"Feb\",\"Mar\",\"Apr\",\"May\",\"Jun\",\"Jul\",\"Aug\",\"Sep\",\"Oct\",\"Nov\",\"Dec\"]\n",
    "FILE_RX = re.compile(r\"(?P<beds>\\d+)_bedroom_(?P<ptype>flat|house)\", re.I)\n",
    "\n",
    "def _clean_cell(x):\n",
    "    if x is None or (isinstance(x, float) and pd.isna(x)):\n",
    "        return None\n",
    "    x = str(x).strip()\n",
    "    return None if x in {\"\", \"-\"} else x\n",
    "\n",
    "def load_and_build_header(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reconstruct 2-row headers like:\n",
    "      row0: 'Mar 2000','Mar 2000','Jun 2000','Jun 2000',...\n",
    "      row1: 'Count','Median','Count','Median',...\n",
    "    -> single-line names: 'Mar 2000_Count', 'Mar 2000_Median', ...\n",
    "    Falls back gracefully if file already has a single header row.\n",
    "    \"\"\"\n",
    "    raw = pd.read_csv(path, header=None, dtype=str)\n",
    "    raw = raw.applymap(lambda x: None if pd.isna(x) else str(x).strip())\n",
    "\n",
    "    r0 = raw.iloc[0].tolist()\n",
    "    r1 = raw.iloc[1].tolist()\n",
    "\n",
    "    def looks_like_two_row_header(r0, r1):\n",
    "        has_month = any(any(m in str(c) for m in MONTH_ABBR) for c in r0)\n",
    "        has_metrics = any(str(c).strip().lower() in {\"count\",\"median\"} for c in r1)\n",
    "        return has_month and has_metrics\n",
    "\n",
    "    if looks_like_two_row_header(r0, r1):\n",
    "        # forward-fill month labels across duplicate pairs\n",
    "        r0_ffill, last = [], None\n",
    "        for c in r0:\n",
    "            if c not in [None,\"\",\"nan\"]:\n",
    "                last = c\n",
    "            r0_ffill.append(last)\n",
    "\n",
    "        cols = []\n",
    "        for i, (top, sub) in enumerate(zip(r0_ffill, r1)):\n",
    "            top = \"Suburb\" if i == 0 else top\n",
    "            name = top if i == 0 else f\"{top}_{sub}\"\n",
    "            cols.append(name)\n",
    "\n",
    "        df = raw.iloc[2:].copy()\n",
    "        df.columns = cols\n",
    "    else:\n",
    "        # already has header row\n",
    "        df = pd.read_csv(path, dtype=str)\n",
    "        if not df.columns[0] or df.columns[0].lower().startswith(\"unnamed\"):\n",
    "            df.rename(columns={df.columns[0]: \"Suburb\"}, inplace=True)\n",
    "\n",
    "    df = df.applymap(_clean_cell)\n",
    "    if \"Suburb\" not in df.columns:\n",
    "        df.rename(columns={df.columns[0]: \"Suburb\"}, inplace=True)\n",
    "\n",
    "    return df.dropna(how=\"all\")\n",
    "\n",
    "def wide_to_tidy(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Collapse '<Mon YYYY>_Count/Median' columns into rows; parse month.\"\"\"\n",
    "    val_cols = [c for c in df.columns if c != \"Suburb\"]\n",
    "    long = df.melt(id_vars=[\"Suburb\"], value_vars=val_cols,\n",
    "                   var_name=\"period_metric\", value_name=\"value\")\n",
    "\n",
    "    ext = long[\"period_metric\"].str.extract(r\"(?P<period>[A-Za-z]{3}\\s+\\d{4})[_\\s-]*(?P<metric>Count|Median)?\")\n",
    "    long[\"period\"] = ext[\"period\"]\n",
    "    long[\"metric\"] = ext[\"metric\"].fillna(\"\")\n",
    "\n",
    "    tidy = (long.pivot_table(index=[\"Suburb\",\"period\"], columns=\"metric\", values=\"value\", aggfunc=\"first\")\n",
    "                 .reset_index())\n",
    "    tidy.columns.name = None\n",
    "\n",
    "    if \"Count\" in tidy.columns:\n",
    "        tidy[\"Count\"] = pd.to_numeric(tidy[\"Count\"], errors=\"coerce\")\n",
    "    if \"Median\" in tidy.columns:\n",
    "        tidy[\"Median\"] = pd.to_numeric(tidy[\"Median\"], errors=\"coerce\")\n",
    "\n",
    "    tidy[\"date\"] = pd.to_datetime(tidy[\"period\"], format=\"%b %Y\", errors=\"coerce\")\n",
    "    tidy = tidy.drop(columns=[\"period\"])\n",
    "\n",
    "    cols = [\"Suburb\",\"date\"] + [c for c in [\"Count\",\"Median\"] if c in tidy.columns]\n",
    "    return tidy[cols].sort_values([\"Suburb\",\"date\"]).reset_index(drop=True)\n",
    "\n",
    "def annotate_from_filename(path: Path) -> dict:\n",
    "    m = FILE_RX.search(path.stem)\n",
    "    if not m:\n",
    "        return {\"bedrooms\": None, \"property_type\": None}\n",
    "    return {\"bedrooms\": int(m.group(\"beds\")), \"property_type\": m.group(\"ptype\").lower()}\n",
    "\n",
    "def process_file(path: Path) -> pd.DataFrame:\n",
    "    df = load_and_build_header(path)\n",
    "    tidy = wide_to_tidy(df)\n",
    "    meta = annotate_from_filename(path)\n",
    "    for k, v in meta.items():\n",
    "        tidy[k] = v\n",
    "    # reorder columns\n",
    "    base = [\"Suburb\",\"date\",\"bedrooms\",\"property_type\"]\n",
    "    vals = [c for c in [\"Count\",\"Median\"] if c in tidy.columns]\n",
    "    return tidy[base + vals]\n",
    "\n",
    "# ---- run on all CSVs ---------------------------------------------------------\n",
    "csvs = sorted(p for p in IN_DIR.glob(\"*.csv\") if not p.name.startswith(\"~$\"))\n",
    "all_frames = []\n",
    "\n",
    "for p in csvs:\n",
    "    t = process_file(p)\n",
    "    t.to_csv(OUT_DIR / f\"{p.stem}_tidy.csv\", index=False)\n",
    "    all_frames.append(t)\n",
    "    print(f\"[ok] {p.name:26s} -> {len(t):5d} rows\")\n",
    "\n",
    "if all_frames:\n",
    "    combo = (pd.concat(all_frames, ignore_index=True)\n",
    "               .sort_values([\"Suburb\",\"date\",\"bedrooms\",\"property_type\"]))\n",
    "    combo.to_csv(OUT_DIR / \"all_properties_tidy.csv\", index=False)\n",
    "    print(f\"\\n[done] Combined -> {OUT_DIR/'all_properties_tidy.csv'}  rows={len(combo):,}\")\n",
    "else:\n",
    "    print(\"No CSVs found to process.\")\n",
    "# ==============================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826373c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ea5901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0881f224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
